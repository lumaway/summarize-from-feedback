{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "open-ai-summarization.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "BWM8S4AvQPR-"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7GVMb1MNYzv"
      },
      "source": [
        "# OpenAI Summarization\n",
        "\n",
        "- [Original Post](https://openai.com/blog/learning-to-summarize-with-human-feedback/)\n",
        "- [Paper](https://arxiv.org/abs/2009.01325)\n",
        "- [Code](https://github.com/openai/summarize-from-feedback)\n",
        "\n",
        "This notebook helps you pass in your own custom data to models mentioned within the paper. The original repo lacked documentation on passing in your own data to play around with it. Also, directly cloning and running it required some modifications to be made to the original code in order to run in a Colab environment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNei7XHzY_ba"
      },
      "source": [
        "## Lumaway's Forked Repo\n",
        "\n",
        "To address these issues, we [forked](https://github.com/lumaway/summarize-from-feedback/) the repo to the Lumaway Github to provide you with those modifications without having to make the changes yourself. _Note: Pull down the 'custom-dataset' branch for now._\n",
        "\n",
        "Please let me know if you find any issues with the code at `sanjay@lumaway.com` :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yl6l9CuGSZm4"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QOorX-F2AF8",
        "outputId": "2cbd8462-ee0c-46d2-fb96-befe235ef6e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Clone Lumaway's fork of the repository.\n",
        "# For now, clone the `custom-dataset` branch.\n",
        "!git clone --branch custom-dataset https://github.com/lumaway/summarize-from-feedback.git\n",
        "\n",
        "%cd \"/content/summarize-from-feedback\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'summarize-from-feedback'...\n",
            "remote: Enumerating objects: 99, done.\u001b[K\n",
            "remote: Counting objects: 100% (99/99), done.\u001b[K\n",
            "remote: Compressing objects: 100% (77/77), done.\u001b[K\n",
            "remote: Total 99 (delta 30), reused 89 (delta 20), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (99/99), done.\n",
            "/content/summarize-from-feedback\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ba9OQ0SQxxx"
      },
      "source": [
        "### Use Python 3.7\n",
        "\n",
        "The `Pipefile` (used by `pipenv`) requires that you require `python3.7`. Unfortunately, Colab runs on Python3.6 and does not allow you to change the default Python version to 3.7 without manually installing it, along with all of the python developer tools."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbDXWdlP9YRc",
        "outputId": "6f580a72-17ea-49be-b86f-5e3ddc30185e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "# Install python 3.7\n",
        "!apt-get install -qq python3.7 python3-setuptools python3.7-dev"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selecting previously unselected package libpython3.7-minimal:amd64.\n",
            "(Reading database ... 144611 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libpython3.7-minimal_3.7.5-2~18.04_amd64.deb ...\n",
            "Unpacking libpython3.7-minimal:amd64 (3.7.5-2~18.04) ...\n",
            "Selecting previously unselected package python3.7-minimal.\n",
            "Preparing to unpack .../1-python3.7-minimal_3.7.5-2~18.04_amd64.deb ...\n",
            "Unpacking python3.7-minimal (3.7.5-2~18.04) ...\n",
            "Selecting previously unselected package libpython3.7-stdlib:amd64.\n",
            "Preparing to unpack .../2-libpython3.7-stdlib_3.7.5-2~18.04_amd64.deb ...\n",
            "Unpacking libpython3.7-stdlib:amd64 (3.7.5-2~18.04) ...\n",
            "Selecting previously unselected package libpython3.7:amd64.\n",
            "Preparing to unpack .../3-libpython3.7_3.7.5-2~18.04_amd64.deb ...\n",
            "Unpacking libpython3.7:amd64 (3.7.5-2~18.04) ...\n",
            "Selecting previously unselected package libpython3.7-dev:amd64.\n",
            "Preparing to unpack .../4-libpython3.7-dev_3.7.5-2~18.04_amd64.deb ...\n",
            "Unpacking libpython3.7-dev:amd64 (3.7.5-2~18.04) ...\n",
            "Selecting previously unselected package python3-pkg-resources.\n",
            "Preparing to unpack .../5-python3-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python3-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python3-setuptools.\n",
            "Preparing to unpack .../6-python3-setuptools_39.0.1-2_all.deb ...\n",
            "Unpacking python3-setuptools (39.0.1-2) ...\n",
            "Selecting previously unselected package python3.7.\n",
            "Preparing to unpack .../7-python3.7_3.7.5-2~18.04_amd64.deb ...\n",
            "Unpacking python3.7 (3.7.5-2~18.04) ...\n",
            "Selecting previously unselected package python3.7-dev.\n",
            "Preparing to unpack .../8-python3.7-dev_3.7.5-2~18.04_amd64.deb ...\n",
            "Unpacking python3.7-dev (3.7.5-2~18.04) ...\n",
            "Setting up libpython3.7-minimal:amd64 (3.7.5-2~18.04) ...\n",
            "Setting up python3-pkg-resources (39.0.1-2) ...\n",
            "Setting up python3.7-minimal (3.7.5-2~18.04) ...\n",
            "Setting up python3-setuptools (39.0.1-2) ...\n",
            "Setting up libpython3.7-stdlib:amd64 (3.7.5-2~18.04) ...\n",
            "Setting up python3.7 (3.7.5-2~18.04) ...\n",
            "Setting up libpython3.7:amd64 (3.7.5-2~18.04) ...\n",
            "Setting up libpython3.7-dev:amd64 (3.7.5-2~18.04) ...\n",
            "Setting up python3.7-dev (3.7.5-2~18.04) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1dBwbfwSdrk"
      },
      "source": [
        "### Install mpich\n",
        "\n",
        "We also install `mpich`.\n",
        "\n",
        "MPICH implements the [Message Passing Interface](https://en.wikipedia.org/wiki/Message_Passing_Interface) standard to take advantage of the parallel computing we have available with the CUDA."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcCo1kBeSe9C",
        "outputId": "af077368-89b7-4455-b0a9-0343d8d3d172",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "# Install mpich\n",
        "!apt install -qq mpich\n",
        "\n",
        "# If that doesn't work, try this:\n",
        "# !apt install -qq libopenmpi-dev"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The following additional packages will be installed:\n",
            "  hwloc-nox libcr-dev libcr0 libmpich-dev libmpich12\n",
            "Suggested packages:\n",
            "  blcr-dkms blcr-util mpich-doc\n",
            "The following NEW packages will be installed:\n",
            "  hwloc-nox libcr-dev libcr0 libmpich-dev libmpich12 mpich\n",
            "0 upgraded, 6 newly installed, 0 to remove and 21 not upgraded.\n",
            "Need to get 2,724 kB of archives.\n",
            "After this operation, 14.0 MB of additional disk space will be used.\n",
            "Selecting previously unselected package libcr0.\n",
            "(Reading database ... 145493 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libcr0_0.8.5-2.3_amd64.deb ...\n",
            "Unpacking libcr0 (0.8.5-2.3) ...\n",
            "Selecting previously unselected package libcr-dev.\n",
            "Preparing to unpack .../1-libcr-dev_0.8.5-2.3_amd64.deb ...\n",
            "Unpacking libcr-dev (0.8.5-2.3) ...\n",
            "Selecting previously unselected package hwloc-nox.\n",
            "Preparing to unpack .../2-hwloc-nox_1.11.9-1_amd64.deb ...\n",
            "Unpacking hwloc-nox (1.11.9-1) ...\n",
            "Selecting previously unselected package libmpich12:amd64.\n",
            "Preparing to unpack .../3-libmpich12_3.3~a2-4_amd64.deb ...\n",
            "Unpacking libmpich12:amd64 (3.3~a2-4) ...\n",
            "Selecting previously unselected package libmpich-dev.\n",
            "Preparing to unpack .../4-libmpich-dev_3.3~a2-4_amd64.deb ...\n",
            "Unpacking libmpich-dev (3.3~a2-4) ...\n",
            "Selecting previously unselected package mpich.\n",
            "Preparing to unpack .../5-mpich_3.3~a2-4_amd64.deb ...\n",
            "Unpacking mpich (3.3~a2-4) ...\n",
            "Setting up hwloc-nox (1.11.9-1) ...\n",
            "Setting up libcr0 (0.8.5-2.3) ...\n",
            "Setting up libcr-dev (0.8.5-2.3) ...\n",
            "Setting up libmpich12:amd64 (3.3~a2-4) ...\n",
            "Setting up libmpich-dev (3.3~a2-4) ...\n",
            "update-alternatives: renaming libmpi.so slave link from /usr/lib/x86_64-linux-gnu/libmpi.so to /usr/lib/libmpi.so\n",
            "update-alternatives: renaming libmpi++.so slave link from /usr/lib/x86_64-linux-gnu/libmpi++.so to /usr/lib/libmpi++.so\n",
            "Setting up mpich (3.3~a2-4) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ys22p_xoSopo"
      },
      "source": [
        "### Install pipenv and library packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwgwIyzEZaWw"
      },
      "source": [
        "Install pipenv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ej4bsURs0e5",
        "outputId": "0f3bb9e1-e00e-4dfa-e249-f587af13f40e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!pip install pipenv --quiet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.9MB 4.7MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.9MB 30.1MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 337kB 54.5MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQIyseSKZWyp"
      },
      "source": [
        "Install library's packages.\n",
        "\n",
        "This takes a while so go grab a coffee or something ‚òï"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bW0KD0MWZfDj",
        "outputId": "e4509b23-8ead-4a4d-8ae0-060c4c9ec2a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "!pipenv install --python python3.7"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[39m\u001b[1mCreating a virtualenv for this project‚Ä¶\u001b[39m\u001b[22m\n",
            "Pipfile: \u001b[31m\u001b[1m/content/summarize-from-feedback/Pipfile\u001b[39m\u001b[22m\n",
            "\u001b[39m\u001b[1mUsing\u001b[39m\u001b[22m \u001b[31m\u001b[1m/usr/bin/python3.7m\u001b[39m\u001b[22m \u001b[32m\u001b[22m(3.7.5)\u001b[39m\u001b[22m \u001b[39m\u001b[1mto create virtualenv‚Ä¶\u001b[39m\u001b[22m\n",
            "‚†π\u001b[0m Creating virtual environment...\u001b[K\u001b[34m\u001b[22mcreated virtual environment CPython3.7.5.final.0-64 in 804ms\n",
            "  creator CPython3Posix(dest=/root/.local/share/virtualenvs/summarize-from-feedback-uqICqDv8, clear=False, global=False)\n",
            "  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/root/.local/share/virtualenv)\n",
            "    added seed packages: pip==20.2.3, setuptools==50.3.1, wheel==0.35.1\n",
            "  activators BashActivator,CShellActivator,FishActivator,PowerShellActivator,PythonActivator,XonshActivator\n",
            "\u001b[39m\u001b[22m\n",
            "\u001b[K\u001b[?25h\u001b[32m\u001b[22m‚úî Successfully created virtual environment!\u001b[39m\u001b[22m\u001b[0m \n",
            "Virtualenv location: \u001b[32m\u001b[22m/root/.local/share/virtualenvs/summarize-from-feedback-uqICqDv8\u001b[39m\u001b[22m\n",
            "\u001b[39m\u001b[1mInstalling dependencies from Pipfile.lock (b50715)‚Ä¶\u001b[39m\u001b[22m\n",
            "  üêç   \u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m 19/19 ‚Äî \u001b[30m\u001b[22m00:01:47\u001b[39m\u001b[22m\n",
            "To activate this project's virtualenv, run \u001b[31m\u001b[22mpipenv shell\u001b[39m\u001b[22m.\n",
            "Alternatively, run a command inside the virtualenv with \u001b[31m\u001b[22mpipenv run\u001b[39m\u001b[22m.\n",
            "\u001b[0m"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcJI1U1wTcM2"
      },
      "source": [
        "## Test Run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZIQReaiZPcy"
      },
      "source": [
        "Run a test experiment with sample-generating code to make sure things are working"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayUWosHX7yTK",
        "outputId": "57e137bf-6a33-47d1-a8a6-4244958a72bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pipenv run exps/sample.py test test-sample"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "copying https://openaipublic.blob.core.windows.net/summarize-from-feedback/models/random-teeny/done-sentinel /tmp/bf-dir-cache/az/openaipublic/summarize-from-feedback/models/random-teeny/done-sentinel\n",
            "copying https://openaipublic.blob.core.windows.net/summarize-from-feedback/models/random-teeny/info.json /tmp/bf-dir-cache/az/openaipublic/summarize-from-feedback/models/random-teeny/info.json\n",
            "copying https://openaipublic.blob.core.windows.net/summarize-from-feedback/models/random-teeny/checkpoint/final_layer_norm_shard_000.pkl /tmp/bf-dir-cache/az/openaipublic/summarize-from-feedback/models/random-teeny/checkpoint/final_layer_norm_shard_000.pkl\n",
            "copying https://openaipublic.blob.core.windows.net/summarize-from-feedback/models/random-teeny/checkpoint/input_embeddings_shard_000.pkl /tmp/bf-dir-cache/az/openaipublic/summarize-from-feedback/models/random-teeny/checkpoint/input_embeddings_shard_000.pkl\n",
            "copying https://openaipublic.blob.core.windows.net/summarize-from-feedback/models/random-teeny/checkpoint/output_head_reward_shard_000.pkl /tmp/bf-dir-cache/az/openaipublic/summarize-from-feedback/models/random-teeny/checkpoint/output_head_reward_shard_000.pkl\n",
            "copying https://openaipublic.blob.core.windows.net/summarize-from-feedback/models/random-teeny/checkpoint/output_head_value_shard_000.pkl /tmp/bf-dir-cache/az/openaipublic/summarize-from-feedback/models/random-teeny/checkpoint/output_head_value_shard_000.pkl\n",
            "copying https://openaipublic.blob.core.windows.net/summarize-from-feedback/models/random-teeny/checkpoint/output_unembeddings_shard_000.pkl /tmp/bf-dir-cache/az/openaipublic/summarize-from-feedback/models/random-teeny/checkpoint/output_unembeddings_shard_000.pkl\n",
            "copying https://openaipublic.blob.core.windows.net/summarize-from-feedback/models/random-teeny/checkpoint/position_embedding_shard_000.pkl /tmp/bf-dir-cache/az/openaipublic/summarize-from-feedback/models/random-teeny/checkpoint/position_embedding_shard_000.pkl\n",
            "copying https://openaipublic.blob.core.windows.net/summarize-from-feedback/models/random-teeny/checkpoint/resblock_0000_shard_000.pkl /tmp/bf-dir-cache/az/openaipublic/summarize-from-feedback/models/random-teeny/checkpoint/resblock_0000_shard_000.pkl\n",
            "copying https://openaipublic.blob.core.windows.net/summarize-from-feedback/models/random-teeny/checkpoint/resblock_0001_shard_000.pkl /tmp/bf-dir-cache/az/openaipublic/summarize-from-feedback/models/random-teeny/checkpoint/resblock_0001_shard_000.pkl\n",
            "copying https://openaipublic.blob.core.windows.net/summarize-from-feedback/models/random-teeny/checkpoint/resblock_0002_shard_000.pkl /tmp/bf-dir-cache/az/openaipublic/summarize-from-feedback/models/random-teeny/checkpoint/resblock_0002_shard_000.pkl\n",
            "copying https://openaipublic.blob.core.windows.net/summarize-from-feedback/models/random-teeny/checkpoint/resblock_0003_shard_000.pkl /tmp/bf-dir-cache/az/openaipublic/summarize-from-feedback/models/random-teeny/checkpoint/resblock_0003_shard_000.pkl\n",
            "Constructing Transformer with the following model hparams:\n",
            "model_H:\n",
            "attn_dropout: 0.0\n",
            "d_model: 64\n",
            "emb_dropout: 0.0\n",
            "fp16_conv_weights: False\n",
            "fp16_embedding_weights: False\n",
            "heads: 2\n",
            "include_pos_embeddings: True\n",
            "init_scale: 1\n",
            "key_bias: False\n",
            "m_attn: 1\n",
            "m_mlp: 2\n",
            "n_ctx: 1024\n",
            "n_layer: 4\n",
            "n_shards: 1\n",
            "res_scale: False\n",
            "resid_dropout: 0.0\n",
            "text_encoding: reversible_50000\n",
            "use_blocksparse_attn: True\n",
            "zero_out: False\n",
            "WARNING:root:d_model of 64 is not divisible by 512 (8*8*8), this means that tensorcores won't be used in attention (CUDA cores will be used instead) and this will results in a ~20% slowdown\n",
            "Loaded model to cuda:0. CUDA memory allocated: 0.03 GB\n",
            "Constructing Transformer with the following model hparams:\n",
            "model_H:\n",
            "attn_dropout: 0.0\n",
            "d_model: 64\n",
            "emb_dropout: 0.0\n",
            "fp16_conv_weights: False\n",
            "fp16_embedding_weights: False\n",
            "heads: 2\n",
            "include_pos_embeddings: True\n",
            "init_scale: 1\n",
            "key_bias: False\n",
            "m_attn: 1\n",
            "m_mlp: 2\n",
            "n_ctx: 1024\n",
            "n_layer: 4\n",
            "n_shards: 1\n",
            "res_scale: False\n",
            "resid_dropout: 0.0\n",
            "text_encoding: reversible_50000\n",
            "use_blocksparse_attn: True\n",
            "zero_out: False\n",
            "WARNING:root:d_model of 64 is not divisible by 512 (8*8*8), this means that tensorcores won't be used in attention (CUDA cores will be used instead) and this will results in a ~20% slowdown\n",
            "Loaded model to cuda:0. CUDA memory allocated: 0.05 GB\n",
            "Samples will be written to /tmp/jobs/test-sample/results/samples.0.jsonl\n",
            "================================================================================\n",
            "RESULT 0 of 8\n",
            "CONTEXT:\n",
            "This is the 7th context in the\n",
            "REF:\n",
            "7th summary in\n",
            "avg logprob -10.875\n",
            "avg orig logprob -10.875\n",
            "SAMPLE 0:\n",
            " adopt intuition laced discussion\n",
            "avg logprob -10.901849746704102\n",
            "avg orig logprob -10.90625\n",
            "SAMPLE 1:\n",
            " humor fewer headline enacted\n",
            "avg logprob -10.784690856933594\n",
            "avg orig logprob -10.78125\n",
            "Batch 1 of 8.  Took 1.4917447566986084 seconds\n",
            "================================================================================\n",
            "RESULT 1 of 8\n",
            "CONTEXT:\n",
            "This is the 8th context in the\n",
            "REF:\n",
            "8th summary in\n",
            "avg logprob -10.7734375\n",
            "avg orig logprob -10.7734375\n",
            "SAMPLE 0:\n",
            "Sheruf backed Sob\n",
            "avg logprob -10.883560180664062\n",
            "avg orig logprob -10.8828125\n",
            "SAMPLE 1:\n",
            " manycci cultivate Sexual\n",
            "avg logprob -10.888951301574707\n",
            "avg orig logprob -10.890625\n",
            "Batch 2 of 8.  Took 0.12869620323181152 seconds\n",
            "================================================================================\n",
            "RESULT 2 of 8\n",
            "CONTEXT:\n",
            "This is the 1th context in the\n",
            "REF:\n",
            "1th summary in\n",
            "avg logprob -10.796875\n",
            "avg orig logprob -10.796875\n",
            "SAMPLE 0:\n",
            " snippetCons LennYes\n",
            "avg logprob -10.67534065246582\n",
            "avg orig logprob -10.671875\n",
            "SAMPLE 1:\n",
            " controversies scorp productivity kinda\n",
            "avg logprob -10.83541488647461\n",
            "avg orig logprob -10.8359375\n",
            "Batch 3 of 8.  Took 0.12678861618041992 seconds\n",
            "================================================================================\n",
            "RESULT 3 of 8\n",
            "CONTEXT:\n",
            "This is the 5th context in the\n",
            "REF:\n",
            "5th summary in\n",
            "avg logprob -10.8046875\n",
            "avg orig logprob -10.8046875\n",
            "SAMPLE 0:\n",
            "raq executives 5000ages\n",
            "avg logprob -10.712273597717285\n",
            "avg orig logprob -10.7109375\n",
            "SAMPLE 1:\n",
            " FEC Factor vigilance institutions\n",
            "avg logprob -10.75094223022461\n",
            "avg orig logprob -10.75\n",
            "Batch 4 of 8.  Took 0.13973402976989746 seconds\n",
            "================================================================================\n",
            "RESULT 4 of 8\n",
            "CONTEXT:\n",
            "This is the 3th context in the\n",
            "REF:\n",
            "3th summary in\n",
            "avg logprob -10.828125\n",
            "avg orig logprob -10.828125\n",
            "SAMPLE 0:\n",
            " Representativeclusivelyitualattack\n",
            "avg logprob -10.828404426574707\n",
            "avg orig logprob -10.828125\n",
            "SAMPLE 1:\n",
            " ionBuyablenai doll\n",
            "avg logprob -10.793928146362305\n",
            "avg orig logprob -10.796875\n",
            "Batch 5 of 8.  Took 0.12198662757873535 seconds\n",
            "================================================================================\n",
            "RESULT 5 of 8\n",
            "CONTEXT:\n",
            "This is the 4th context in the\n",
            "REF:\n",
            "4th summary in\n",
            "avg logprob -10.84375\n",
            "avg orig logprob -10.84375\n",
            "SAMPLE 0:\n",
            "alla grandson vinegar iCloud\n",
            "avg logprob -11.015113830566406\n",
            "avg orig logprob -11.015625\n",
            "SAMPLE 1:\n",
            "elling Pf dope\"‚Äî\n",
            "avg logprob -10.874868392944336\n",
            "avg orig logprob -10.875\n",
            "Batch 6 of 8.  Took 0.10372447967529297 seconds\n",
            "================================================================================\n",
            "RESULT 6 of 8\n",
            "CONTEXT:\n",
            "This is the 2th context in the\n",
            "REF:\n",
            "2th summary in\n",
            "avg logprob -10.7890625\n",
            "avg orig logprob -10.7890625\n",
            "SAMPLE 0:\n",
            " detectives spokenitherdoc\n",
            "avg logprob -10.860418319702148\n",
            "avg orig logprob -10.859375\n",
            "SAMPLE 1:\n",
            "bour Vim galleryGy\n",
            "avg logprob -10.957168579101562\n",
            "avg orig logprob -10.953125\n",
            "Batch 7 of 8.  Took 0.11199498176574707 seconds\n",
            "================================================================================\n",
            "RESULT 7 of 8\n",
            "CONTEXT:\n",
            "This is the 0th context in the\n",
            "REF:\n",
            "0th summary in\n",
            "avg logprob -10.7109375\n",
            "avg orig logprob -10.7109375\n",
            "SAMPLE 0:\n",
            " incap final herpes undergrad\n",
            "avg logprob -10.87211799621582\n",
            "avg orig logprob -10.875\n",
            "SAMPLE 1:\n",
            " meals physicempt/_\n",
            "avg logprob -10.790451049804688\n",
            "avg orig logprob -10.7890625\n",
            "Batch 8 of 8.  Took 0.10049939155578613 seconds\n",
            "[cbe1cda1848b:01350] *** Process received signal ***\n",
            "[cbe1cda1848b:01350] Signal: Segmentation fault (11)\n",
            "[cbe1cda1848b:01350] Signal code: Address not mapped (1)\n",
            "[cbe1cda1848b:01350] Failing at address: 0x7f3c9103720d\n",
            "[cbe1cda1848b:01350] [ 0] /lib/x86_64-linux-gnu/libpthread.so.0(+0x128a0)[0x7f3c940e98a0]\n",
            "[cbe1cda1848b:01350] [ 1] /lib/x86_64-linux-gnu/libc.so.6(getenv+0xa5)[0x7f3c93d28835]\n",
            "[cbe1cda1848b:01350] [ 2] /usr/lib/x86_64-linux-gnu/libtcmalloc.so.4(_ZN13TCMallocGuardD1Ev+0x34)[0x7f3c94593e44]\n",
            "[cbe1cda1848b:01350] [ 3] /lib/x86_64-linux-gnu/libc.so.6(__cxa_finalize+0xf5)[0x7f3c93d296c5]\n",
            "[cbe1cda1848b:01350] [ 4] /usr/lib/x86_64-linux-gnu/libtcmalloc.so.4(+0x13cb3)[0x7f3c94591cb3]\n",
            "[cbe1cda1848b:01350] *** End of error message ***\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjtI460VZS9V"
      },
      "source": [
        "Test the reward model evaluation code to make sure things are working"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afvxnYQU8S8u",
        "outputId": "f79ab6e8-549c-41a2-f6a4-7cb0866f6a3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        }
      },
      "source": [
        "!pipenv run exps/eval_rm.py test test-eval"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Constructing Transformer with the following model hparams:\n",
            "model_H:\n",
            "attn_dropout: 0.0\n",
            "d_model: 64\n",
            "emb_dropout: 0.0\n",
            "fp16_conv_weights: False\n",
            "fp16_embedding_weights: False\n",
            "heads: 2\n",
            "include_pos_embeddings: True\n",
            "init_scale: 1\n",
            "key_bias: False\n",
            "m_attn: 1\n",
            "m_mlp: 2\n",
            "n_ctx: 1024\n",
            "n_layer: 4\n",
            "n_shards: 1\n",
            "res_scale: False\n",
            "resid_dropout: 0.0\n",
            "text_encoding: reversible_50000\n",
            "use_blocksparse_attn: True\n",
            "zero_out: False\n",
            "WARNING:root:d_model of 64 is not divisible by 512 (8*8*8), this means that tensorcores won't be used in attention (CUDA cores will be used instead) and this will results in a ~20% slowdown\n",
            "Loaded model to cuda:0. CUDA memory allocated: 0.01 GB\n",
            "Outputs will be written to /tmp/jobs/test-eval/results/samples.0.jsonl\n",
            "copying https://openaipublic.blob.core.windows.net/summarize-from-feedback/samples/test/samples.0.jsonl /tmp/bf-dir-cache/az/openaipublic/summarize-from-feedback/samples/test/samples.0.jsonl\n",
            "copying https://openaipublic.blob.core.windows.net/summarize-from-feedback/samples/test/task_hparams.json /tmp/bf-dir-cache/az/openaipublic/summarize-from-feedback/samples/test/task_hparams.json\n",
            "Batch 1.  Took 0.014570474624633789 seconds\n",
            "Batch 2.  Took 0.007987499237060547 seconds\n",
            "Batch 3.  Took 0.007978439331054688 seconds\n",
            "Batch 4.  Took 0.007855653762817383 seconds\n",
            "Batch 5.  Took 0.007808685302734375 seconds\n",
            "Batch 6.  Took 0.007826805114746094 seconds\n",
            "Batch 7.  Took 0.007834672927856445 seconds\n",
            "Batch 8.  Took 0.007903575897216797 seconds\n",
            "Wrote 8 batches to /tmp/jobs/test-eval/results/samples.0.jsonl\n",
            "Mean reward: 0.373\n",
            "Stddev within a query: 0.686\n",
            "Stddev across queries: 0.996\n",
            "[38bb5be42c7d:01446] *** Process received signal ***\n",
            "[38bb5be42c7d:01446] Signal: Segmentation fault (11)\n",
            "[38bb5be42c7d:01446] Signal code: Address not mapped (1)\n",
            "[38bb5be42c7d:01446] Failing at address: 0x7f7f4460620d\n",
            "[38bb5be42c7d:01446] [ 0] /lib/x86_64-linux-gnu/libpthread.so.0(+0x128a0)[0x7f7f476b88a0]\n",
            "[38bb5be42c7d:01446] [ 1] /lib/x86_64-linux-gnu/libc.so.6(getenv+0xa5)[0x7f7f472f7835]\n",
            "[38bb5be42c7d:01446] [ 2] /usr/lib/x86_64-linux-gnu/libtcmalloc.so.4(_ZN13TCMallocGuardD1Ev+0x34)[0x7f7f47b62e44]\n",
            "[38bb5be42c7d:01446] [ 3] /lib/x86_64-linux-gnu/libc.so.6(__cxa_finalize+0xf5)[0x7f7f472f86c5]\n",
            "[38bb5be42c7d:01446] [ 4] /usr/lib/x86_64-linux-gnu/libtcmalloc.so.4(+0x13cb3)[0x7f7f47b60cb3]\n",
            "[38bb5be42c7d:01446] *** End of error message ***\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sS3lu9usTRKS"
      },
      "source": [
        "View the test eval samples generated"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwDOpycW85w4",
        "outputId": "77b782f5-41a0-4513-8f2b-856964ce32a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "!cat /tmp/jobs/test-eval/results/samples.0.jsonl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"context\": \"This is the 7th context in the\", \"samples\": [\" Absent 1934 quantazing\", \" Socrates compressedHaunted programmed\"], \"ref\": \"7th summary in\", \"extra_fields\": {\"query\": \"This is the 7th context in the dataset train split\"}, \"__np_context_tokens\": {\"shape\": [8], \"dtype\": \"int64\", \"data\": \"vAQAAAAAAAA+AQAAAAAAAAYBAAAAAAAA/wIAAAAAAACQAQAAAAAAAHwSAAAAAAAAHwEAAAAAAAAGAQAAAAAAAA==\"}, \"__np_sample_tokens\": {\"shape\": [2, 4], \"dtype\": \"int64\", \"data\": \"esAAAAAAAAB0cgAAAAAAALIVAAAAAAAA5g8AAAAAAAAaoQAAAAAAACxjAAAAAAAAg7cAAAAAAAAKawAAAAAAAA==\"}, \"__np_logprobs\": {\"shape\": [2, 4], \"dtype\": \"float32\", \"data\": \"5A4pwY+8K8Fl0irBL9wrwWR8KcGlEzLBpYMuwZFaLME=\"}, \"__np_orig_logprobs\": {\"shape\": [2, 4], \"dtype\": \"float16\", \"data\": \"SMleyVfJX8lMyZHJdMljyQ==\"}, \"__np_ref_tokens\": {\"shape\": [4], \"dtype\": \"int64\", \"data\": \"FgAAAAAAAACQAQAAAAAAAI4pAAAAAAAAHwEAAAAAAAA=\"}, \"__np_ref_logprobs\": {\"shape\": [4], \"dtype\": \"float16\", \"data\": \"fMmNyVXJX8k=\"}, \"__np_orig_ref_logprobs\": {\"shape\": [4], \"dtype\": \"float16\", \"data\": \"fMmNyVXJX8k=\"}, \"__np_predicted_reward\": {\"shape\": [2], \"dtype\": \"float32\", \"data\": \"YlDAP996Ur8=\"}}\n",
            "{\"context\": \"This is the 8th context in the\", \"samples\": [\"ReplyWare embold illustrate\", \" LIB 1940 writesepend\"], \"ref\": \"8th summary in\", \"extra_fields\": {\"query\": \"This is the 8th context in the dataset train split\"}, \"__np_context_tokens\": {\"shape\": [8], \"dtype\": \"int64\", \"data\": \"vAQAAAAAAAA+AQAAAAAAAAYBAAAAAAAAJwMAAAAAAACQAQAAAAAAAHwSAAAAAAAAHwEAAAAAAAAGAQAAAAAAAA==\"}, \"__np_sample_tokens\": {\"shape\": [2, 4], \"dtype\": \"int64\", \"data\": \"C5AAAAAAAAColwAAAAAAAO2kAAAAAAAA2ksAAAAAAABTsgAAAAAAAGw/AAAAAAAAjRoAAAAAAACCCgAAAAAAAA==\"}, \"__np_logprobs\": {\"shape\": [2, 4], \"dtype\": \"float32\", \"data\": \"4kcswbgQL8GvoivBYysvwaKXLsEO0y3BoEwqwQwTLME=\"}, \"__np_orig_logprobs\": {\"shape\": [2, 4], \"dtype\": \"float16\", \"data\": \"Ysl5yV3Jecl1yW/JUslhyQ==\"}, \"__np_ref_tokens\": {\"shape\": [4], \"dtype\": \"int64\", \"data\": \"FwAAAAAAAACQAQAAAAAAAI4pAAAAAAAAHwEAAAAAAAA=\"}, \"__np_ref_logprobs\": {\"shape\": [4], \"dtype\": \"float16\", \"data\": \"ecleyVjJXck=\"}, \"__np_orig_ref_logprobs\": {\"shape\": [4], \"dtype\": \"float16\", \"data\": \"ecleyVjJXck=\"}, \"__np_predicted_reward\": {\"shape\": [2], \"dtype\": \"float32\", \"data\": \"fkEMvwA8qz8=\"}}\n",
            "{\"context\": \"This is the 1th context in the\", \"samples\": [\"restrial developed\\\");kos\", \" hilarious servicing River284\"], \"ref\": \"1th summary in\", \"extra_fields\": {\"query\": \"This is the 1th context in the dataset train split\"}, \"__np_context_tokens\": {\"shape\": [8], \"dtype\": \"int64\", \"data\": \"vAQAAAAAAAA+AQAAAAAAAAYBAAAAAAAAYAEAAAAAAACQAQAAAAAAAHwSAAAAAAAAHwEAAAAAAAAGAQAAAAAAAA==\"}, \"__np_sample_tokens\": {\"shape\": [2, 4], \"dtype\": \"int64\", \"data\": \"4lsAAAAAAABGEAAAAAAAAO07AAAAAAAARrQAAAAAAACJTgAAAAAAAFKpAAAAAAAA6hYAAAAAAACAdgAAAAAAAA==\"}, \"__np_logprobs\": {\"shape\": [2, 4], \"dtype\": \"float32\", \"data\": \"ZBopwUe+L8FvGCzBitctwUSjLMGnHyvB02gowewgL8E=\"}, \"__np_orig_logprobs\": {\"shape\": [2, 4], \"dtype\": \"float16\", \"data\": \"Scl+yWHJb8llyVnJQ8l5yQ==\"}, \"__np_ref_tokens\": {\"shape\": [4], \"dtype\": \"int64\", \"data\": \"EAAAAAAAAACQAQAAAAAAAI4pAAAAAAAAHwEAAAAAAAA=\"}, \"__np_ref_logprobs\": {\"shape\": [4], \"dtype\": \"float16\", \"data\": \"VcmMyVfJYsk=\"}, \"__np_orig_ref_logprobs\": {\"shape\": [4], \"dtype\": \"float16\", \"data\": \"VcmMyVfJYsk=\"}, \"__np_predicted_reward\": {\"shape\": [2], \"dtype\": \"float32\", \"data\": \"wbVnPrIixT8=\"}}\n",
            "{\"context\": \"This is the 5th context in the\", \"samples\": [\"LGBT\\\"- cereal Spotify\", \" Hivesomeone Hal undersc\"], \"ref\": \"5th summary in\", \"extra_fields\": {\"query\": \"This is the 5th context in the dataset train split\"}, \"__np_context_tokens\": {\"shape\": [8], \"dtype\": \"int64\", \"data\": \"vAQAAAAAAAA+AQAAAAAAAAYBAAAAAAAAggIAAAAAAACQAQAAAAAAAHwSAAAAAAAAHwEAAAAAAAAGAQAAAAAAAA==\"}, \"__np_sample_tokens\": {\"shape\": [2, 4], \"dtype\": \"int64\", \"data\": \"RZMAAAAAAACpaAAAAAAAAIaBAAAAAAAAmmgAAAAAAADTgQAAAAAAAKi0AAAAAAAADysAAAAAAADAbAAAAAAAAA==\"}, \"__np_logprobs\": {\"shape\": [2, 4], \"dtype\": \"float32\", \"data\": \"yg4xweQxJ8FVii7Bf9IqwcqbMMF1ui/BK28xwcddK8E=\"}, \"__np_orig_logprobs\": {\"shape\": [2, 4], \"dtype\": \"float16\", \"data\": \"iMk6yXTJV8mFyX7Ji8lbyQ==\"}, \"__np_ref_tokens\": {\"shape\": [4], \"dtype\": \"int64\", \"data\": \"FAAAAAAAAACQAQAAAAAAAI4pAAAAAAAAHwEAAAAAAAA=\"}, \"__np_ref_logprobs\": {\"shape\": [4], \"dtype\": \"float16\", \"data\": \"XMmOyVXJXMk=\"}, \"__np_orig_ref_logprobs\": {\"shape\": [4], \"dtype\": \"float16\", \"data\": \"XMmOyVXJXMk=\"}, \"__np_predicted_reward\": {\"shape\": [2], \"dtype\": \"float32\", \"data\": \"+lskv0Q6QL8=\"}}\n",
            "{\"context\": \"This is the 3th context in the\", \"samples\": [\" wristsillerybroad psychopath\", \" mot Mahmoud Publisher ratt\"], \"ref\": \"3th summary in\", \"extra_fields\": {\"query\": \"This is the 3th context in the dataset train split\"}, \"__np_context_tokens\": {\"shape\": [8], \"dtype\": \"int64\", \"data\": \"vAQAAAAAAAA+AQAAAAAAAAYBAAAAAAAAAQIAAAAAAACQAQAAAAAAAHwSAAAAAAAAHwEAAAAAAAAGAQAAAAAAAA==\"}, \"__np_sample_tokens\": {\"shape\": [2, 4], \"dtype\": \"int64\", \"data\": \"E5UAAAAAAABIOgAAAAAAAC6PAAAAAAAA5nMAAAAAAABBCQAAAAAAAJqWAAAAAAAAjW0AAAAAAAB/agAAAAAAAA==\"}, \"__np_logprobs\": {\"shape\": [2, 4], \"dtype\": \"float32\", \"data\": \"o5QyweWAK8Ebty3BMKwuwWNaLcFu3SzB6akrwQrFLsE=\"}, \"__np_orig_logprobs\": {\"shape\": [2, 4], \"dtype\": \"float16\", \"data\": \"lclcyW7JdclryWfJXcl2yQ==\"}, \"__np_ref_tokens\": {\"shape\": [4], \"dtype\": \"int64\", \"data\": \"EgAAAAAAAACQAQAAAAAAAI4pAAAAAAAAHwEAAAAAAAA=\"}, \"__np_ref_logprobs\": {\"shape\": [4], \"dtype\": \"float16\", \"data\": \"bMmKyVbJXMk=\"}, \"__np_orig_ref_logprobs\": {\"shape\": [4], \"dtype\": \"float16\", \"data\": \"bMmKyVbJXMk=\"}, \"__np_predicted_reward\": {\"shape\": [2], \"dtype\": \"float32\", \"data\": \"iH+nP3IQAUA=\"}}\n",
            "{\"context\": \"This is the 4th context in the\", \"samples\": [\" careginstance reside dazzling\", \" Um Integer Goldman monumental\"], \"ref\": \"4th summary in\", \"extra_fields\": {\"query\": \"This is the 4th context in the dataset train split\"}, \"__np_context_tokens\": {\"shape\": [8], \"dtype\": \"int64\", \"data\": \"vAQAAAAAAAA+AQAAAAAAAAYBAAAAAAAAXAIAAAAAAACQAQAAAAAAAHwSAAAAAAAAHwEAAAAAAAAGAQAAAAAAAA==\"}, \"__np_sample_tokens\": {\"shape\": [2, 4], \"dtype\": \"int64\", \"data\": \"gn4AAAAAAAC6mAAAAAAAACxnAAAAAAAAP6IAAAAAAAAvUgAAAAAAAF6FAAAAAAAANEkAAAAAAAAMjgAAAAAAAA==\"}, \"__np_logprobs\": {\"shape\": [2, 4], \"dtype\": \"float32\", \"data\": \"7fcnwXOULMHKRS3Byjotwe1JMMFusizB6VswwbDcMME=\"}, \"__np_orig_logprobs\": {\"shape\": [2, 4], \"dtype\": \"float16\", \"data\": \"QMllyWrJasmCyWbJg8mHyQ==\"}, \"__np_ref_tokens\": {\"shape\": [4], \"dtype\": \"int64\", \"data\": \"EwAAAAAAAACQAQAAAAAAAI4pAAAAAAAAHwEAAAAAAAA=\"}, \"__np_ref_logprobs\": {\"shape\": [4], \"dtype\": \"float16\", \"data\": \"dsmLyVPJW8k=\"}, \"__np_orig_ref_logprobs\": {\"shape\": [4], \"dtype\": \"float16\", \"data\": \"dsmLyVPJW8k=\"}, \"__np_predicted_reward\": {\"shape\": [2], \"dtype\": \"float32\", \"data\": \"EZJxvmV93r4=\"}}\n",
            "{\"context\": \"This is the 2th context in the\", \"samples\": [\"312 exits StartupVirginia\", \"ariannatural indirectlyANI\"], \"ref\": \"2th summary in\", \"extra_fields\": {\"query\": \"This is the 2th context in the dataset train split\"}, \"__np_context_tokens\": {\"shape\": [8], \"dtype\": \"int64\", \"data\": \"vAQAAAAAAAA+AQAAAAAAAAYBAAAAAAAAagEAAAAAAACQAQAAAAAAAHwSAAAAAAAAHwEAAAAAAAAGAQAAAAAAAA==\"}, \"__np_sample_tokens\": {\"shape\": [2, 4], \"dtype\": \"int64\", \"data\": \"Qm0AAAAAAADHdQAAAAAAABieAAAAAAAAOaAAAAAAAABzDgAAAAAAABouAAAAAAAAGlEAAAAAAACQqgAAAAAAAA==\"}, \"__np_logprobs\": {\"shape\": [2, 4], \"dtype\": \"float32\", \"data\": \"FEUqwa0fLsF/3C3Bt6QqwZSZLsEZKyzBV2cpwV0tKcE=\"}, \"__np_orig_logprobs\": {\"shape\": [2, 4], \"dtype\": \"float16\", \"data\": \"UslxyW/JVcl1yWHJS8lJyQ==\"}, \"__np_ref_tokens\": {\"shape\": [4], \"dtype\": \"int64\", \"data\": \"EQAAAAAAAACQAQAAAAAAAI4pAAAAAAAAHwEAAAAAAAA=\"}, \"__np_ref_logprobs\": {\"shape\": [4], \"dtype\": \"float16\", \"data\": \"XMmDyVrJW8k=\"}, \"__np_orig_ref_logprobs\": {\"shape\": [4], \"dtype\": \"float16\", \"data\": \"XMmDyVrJW8k=\"}, \"__np_predicted_reward\": {\"shape\": [2], \"dtype\": \"float32\", \"data\": \"FD4Dv0SbRT0=\"}}\n",
            "{\"context\": \"This is the 0th context in the\", \"samples\": [\"\\\"\\u2026ioned Spencer zip\", \" corrupt Kiss Introdupread\"], \"ref\": \"0th summary in\", \"extra_fields\": {\"query\": \"This is the 0th context in the dataset train split\"}, \"__np_context_tokens\": {\"shape\": [8], \"dtype\": \"int64\", \"data\": \"vAQAAAAAAAA+AQAAAAAAAAYBAAAAAAAAkQIAAAAAAACQAQAAAAAAAHwSAAAAAAAAHwEAAAAAAAAGAQAAAAAAAA==\"}, \"__np_sample_tokens\": {\"shape\": [2, 4], \"dtype\": \"int64\", \"data\": \"al8AAAAAAACSOgAAAAAAAGM+AAAAAAAABk4AAAAAAAB+KQAAAAAAAH5PAAAAAAAAHCsAAAAAAADRJQAAAAAAAA==\"}, \"__np_logprobs\": {\"shape\": [2, 4], \"dtype\": \"float32\", \"data\": \"vMYswXvcKcGgaynBRqAswfy5K8GQiyvBp5gswayAK8E=\"}, \"__np_orig_logprobs\": {\"shape\": [2, 4], \"dtype\": \"float16\", \"data\": \"ZslPyUvJZcleyVzJZclcyQ==\"}, \"__np_ref_tokens\": {\"shape\": [4], \"dtype\": \"int64\", \"data\": \"DwAAAAAAAACQAQAAAAAAAI4pAAAAAAAAHwEAAAAAAAA=\"}, \"__np_ref_logprobs\": {\"shape\": [4], \"dtype\": \"float16\", \"data\": \"SslnyV3JXsk=\"}, \"__np_orig_ref_logprobs\": {\"shape\": [4], \"dtype\": \"float16\", \"data\": \"SslnyV3JXsk=\"}, \"__np_predicted_reward\": {\"shape\": [2], \"dtype\": \"float32\", \"data\": \"aYcjPwOnpT8=\"}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yqX9RoiTeQ8"
      },
      "source": [
        "## Running Your Own Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeKbRLtdY8G4"
      },
      "source": [
        "`exps/sample.py` is the file generating the summaries. To run it through your own data, it helps to understand how running `exps/sample.py` works. \n",
        "\n",
        "```shell\n",
        "!pipenv run exps/sample.py <experiment_name> <output_dir> --num_queries N\n",
        "```\n",
        "\n",
        "Where\n",
        "- `<experiment_name>` is the name of the experiment you'd like to run.\n",
        "  - Must be defined in the `exps/sample.py` file.\n",
        "  - We added a custom experiment ('`custom_experiment`') in the forked repo.\n",
        "- `<output_dir>` is output director of where the generated summary samples are generated.\n",
        "- `N` is the number of queries you would like to run. This must be <= len(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYq9CtZTTtPe",
        "outputId": "3f9161ad-f7a3-4e53-d8ce-3c2950578bc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pipenv run exps/sample.py custom_experiment ce_output_dir --num_queries 2"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NOTE: overriding key num_queries from 128 to 2\n",
            "Constructing Transformer with the following model hparams:\n",
            "model_H:\n",
            "attn_dropout: 0.0\n",
            "d_model: 64\n",
            "emb_dropout: 0.0\n",
            "fp16_conv_weights: False\n",
            "fp16_embedding_weights: False\n",
            "heads: 2\n",
            "include_pos_embeddings: True\n",
            "init_scale: 1\n",
            "key_bias: False\n",
            "m_attn: 1\n",
            "m_mlp: 2\n",
            "n_ctx: 1024\n",
            "n_layer: 4\n",
            "n_shards: 1\n",
            "res_scale: False\n",
            "resid_dropout: 0.0\n",
            "text_encoding: reversible_50000\n",
            "use_blocksparse_attn: True\n",
            "zero_out: False\n",
            "WARNING:root:d_model of 64 is not divisible by 512 (8*8*8), this means that tensorcores won't be used in attention (CUDA cores will be used instead) and this will results in a ~20% slowdown\n",
            "Loaded model to cuda:0. CUDA memory allocated: 0.03 GB\n",
            "Samples will be written to /tmp/jobs/ce_output_dir/results/samples.0.jsonl\n",
            "================================================================================\n",
            "RESULT 0 of 2\n",
            "CONTEXT:\n",
            "                                                                                                                                                                                                                                                                                          SUBREDDIT: r/AskReddit\n",
            "\n",
            "TITLE: How do you get someone out of your head?\n",
            "\n",
            "POST: Hi,\n",
            "I'm 22, and I have been with my girlfriend for 5 years now. We recently moved together. We've always loved each other intensely.\n",
            "\n",
            "Problem, I recently started to have feelings for an other person (a friend). This person has had a boyfriend for now 3 years, and has absolutely no ideas. Those feelings were so strong, it was hard to hide them. After 2 months of me being distant and really sad, my girlfriend forced me to say what was bothering me. I'm not a good liar, and now she knows.\n",
            "\n",
            "We decided to give us a week alone, I went to my parents. \n",
            "\n",
            "Now, I'm completely lost. I keep on thinking about this person, and I hate that. I would like for those feelings to go away, to leave me alone. But I can't.  \n",
            "\n",
            "What do I do? It's been 3 months now, and I'm just desperate.\n",
            "\n",
            "TL;DR:\n",
            "REF:\n",
            " long relationship; fell in love with an other person; admitted it; would like it to disappear, though it doesn't.\n",
            "avg logprob -10.817307692307692\n",
            "SAMPLE 0:\n",
            " EvangelDX TOP tilt existence Festival *)ader relationship :=326 cavalry relationship relationship relationship√•sylvania dualRepresentnoeconom326 mannedeconomÔøΩ Festival326 learnhumane Versehop ÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩeconomÔøΩ Festival *)adereconom326aderolvesno CzechÔøΩ outstandingBefore whistleblowershumane\n",
            "avg logprob -0.38302048047383624\n",
            "Batch 1 of 2.  Took 3.1483256816864014 seconds\n",
            "================================================================================\n",
            "RESULT 1 of 2\n",
            "CONTEXT:\n",
            "                                                                                                                                                                                                                                                                                          SUBREDDIT: r/AskReddit\n",
            "\n",
            "TITLE: How do you get someone out of your head?\n",
            "\n",
            "POST: Hi,\n",
            "I'm 22, and I have been with my girlfriend for 5 years now. We recently moved together. We've always loved each other intensely.\n",
            "\n",
            "Problem, I recently started to have feelings for an other person (a friend). This person has had a boyfriend for now 3 years, and has absolutely no ideas. Those feelings were so strong, it was hard to hide them. After 2 months of me being distant and really sad, my girlfriend forced me to say what was bothering me. I'm not a good liar, and now she knows.\n",
            "\n",
            "We decided to give us a week alone, I went to my parents. \n",
            "\n",
            "Now, I'm completely lost. I keep on thinking about this person, and I hate that. I would like for those feelings to go away, to leave me alone. But I can't.  \n",
            "\n",
            "What do I do? It's been 3 months now, and I'm just desperate.\n",
            "\n",
            "TL;DR:\n",
            "REF:\n",
            " long relationship; fell in love with an other person; admitted it; would like it to disappear, though it doesn't.\n",
            "avg logprob -10.817307692307692\n",
            "SAMPLE 0:\n",
            "humane *) Australians Ended elaboratedkiss ${olk immenselynoHoweverBefore cavalry relationship relationship√•sylvania dualRepresent elaboratedkiss outstanding frequenciesofficesylvania 290 relationshipeconomÔøΩ Festival *)kisseconomÔøΩ Festival *)adereconomnoeconomÔøΩno Federal immenselyeconomÔøΩBefore whistleblowers\n",
            "avg logprob -0.5730454126993815\n",
            "Batch 2 of 2.  Took 0.4030342102050781 seconds\n",
            "[cbe1cda1848b:01665] *** Process received signal ***\n",
            "[cbe1cda1848b:01665] Signal: Segmentation fault (11)\n",
            "[cbe1cda1848b:01665] Signal code: Address not mapped (1)\n",
            "[cbe1cda1848b:01665] Failing at address: 0x7f72a905b20d\n",
            "[cbe1cda1848b:01665] [ 0] /lib/x86_64-linux-gnu/libpthread.so.0(+0x128a0)[0x7f72ac10d8a0]\n",
            "[cbe1cda1848b:01665] [ 1] /lib/x86_64-linux-gnu/libc.so.6(getenv+0xa5)[0x7f72abd4c835]\n",
            "[cbe1cda1848b:01665] [ 2] /usr/lib/x86_64-linux-gnu/libtcmalloc.so.4(_ZN13TCMallocGuardD1Ev+0x34)[0x7f72ac5b7e44]\n",
            "[cbe1cda1848b:01665] [ 3] /lib/x86_64-linux-gnu/libc.so.6(__cxa_finalize+0xf5)[0x7f72abd4d6c5]\n",
            "[cbe1cda1848b:01665] [ 4] /usr/lib/x86_64-linux-gnu/libtcmalloc.so.4(+0x13cb3)[0x7f72ac5b5cb3]\n",
            "[cbe1cda1848b:01665] *** End of error message ***\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHF7RUOCTwiE"
      },
      "source": [
        "### Evaluate generated summaries\n",
        "\n",
        "Supply `--input_path <dir>` to the eval.py function to specify which samples you'd like the reward model (`rm4` here) to evaluate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y29KlSkC-Ejr",
        "outputId": "b710bdfa-9663-4c18-9f33-71fece86f6a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        }
      },
      "source": [
        "!pipenv run exps/eval_rm.py custom_eval eval-custom --input_path /tmp/jobs/ce_output_dir/results/\n",
        "\n",
        "# Uncomment for rm4 eval results\n",
        "# !pipenv run exps/eval_rm.py rm4 eval-rm4 --input_path /tmp/jobs/ce_output_dir/results/"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NOTE: overriding key input_path from summarize-from-feedback/samples/test to /tmp/jobs/ce_output_dir/results/\n",
            "Constructing Transformer with the following model hparams:\n",
            "model_H:\n",
            "attn_dropout: 0.0\n",
            "d_model: 64\n",
            "emb_dropout: 0.0\n",
            "fp16_conv_weights: False\n",
            "fp16_embedding_weights: False\n",
            "heads: 2\n",
            "include_pos_embeddings: True\n",
            "init_scale: 1\n",
            "key_bias: False\n",
            "m_attn: 1\n",
            "m_mlp: 2\n",
            "n_ctx: 1024\n",
            "n_layer: 4\n",
            "n_shards: 1\n",
            "res_scale: False\n",
            "resid_dropout: 0.0\n",
            "text_encoding: reversible_50000\n",
            "use_blocksparse_attn: True\n",
            "zero_out: False\n",
            "WARNING:root:d_model of 64 is not divisible by 512 (8*8*8), this means that tensorcores won't be used in attention (CUDA cores will be used instead) and this will results in a ~20% slowdown\n",
            "Loaded model to cuda:0. CUDA memory allocated: 0.01 GB\n",
            "Outputs will be written to /tmp/jobs/eval-custom/results/samples.0.jsonl\n",
            "Batch 1.  Took 0.013067245483398438 seconds\n",
            "Batch 2.  Took 0.007326602935791016 seconds\n",
            "Wrote 2 batches to /tmp/jobs/eval-custom/results/samples.0.jsonl\n",
            "Mean reward: 0.990\n",
            "Stddev across queries: 0.12\n",
            "[cbe1cda1848b:01851] *** Process received signal ***\n",
            "[cbe1cda1848b:01851] Signal: Segmentation fault (11)\n",
            "[cbe1cda1848b:01851] Signal code: Address not mapped (1)\n",
            "[cbe1cda1848b:01851] Failing at address: 0x7f89df88120d\n",
            "[cbe1cda1848b:01851] [ 0] /lib/x86_64-linux-gnu/libpthread.so.0(+0x128a0)[0x7f89e29338a0]\n",
            "[cbe1cda1848b:01851] [ 1] /lib/x86_64-linux-gnu/libc.so.6(getenv+0xa5)[0x7f89e2572835]\n",
            "[cbe1cda1848b:01851] [ 2] /usr/lib/x86_64-linux-gnu/libtcmalloc.so.4(_ZN13TCMallocGuardD1Ev+0x34)[0x7f89e2ddde44]\n",
            "[cbe1cda1848b:01851] [ 3] /lib/x86_64-linux-gnu/libc.so.6(__cxa_finalize+0xf5)[0x7f89e25736c5]\n",
            "[cbe1cda1848b:01851] [ 4] /usr/lib/x86_64-linux-gnu/libtcmalloc.so.4(+0x13cb3)[0x7f89e2ddbcb3]\n",
            "[cbe1cda1848b:01851] *** End of error message ***\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzXOPKtBh4ju",
        "outputId": "16e7b253-74e2-4f0d-b641-e4f3de779af3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "!cat /tmp/jobs/eval-custom/results/samples.0.jsonl "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"context\": \"                                                                                                                                                                                                                                                                                          SUBREDDIT: r/AskReddit\\n\\nTITLE: How do you get someone out of your head?\\n\\nPOST: Hi,\\nI'm 22, and I have been with my girlfriend for 5 years now. We recently moved together. We've always loved each other intensely.\\n\\nProblem, I recently started to have feelings for an other person (a friend). This person has had a boyfriend for now 3 years, and has absolutely no ideas. Those feelings were so strong, it was hard to hide them. After 2 months of me being distant and really sad, my girlfriend forced me to say what was bothering me. I'm not a good liar, and now she knows.\\n\\nWe decided to give us a week alone, I went to my parents. \\n\\nNow, I'm completely lost. I keep on thinking about this person, and I hate that. I would like for those feelings to go away, to leave me alone. But I can't.  \\n\\nWhat do I do? It's been 3 months now, and I'm just desperate.\\n\\nTL;DR:\", \"samples\": [\" EvangelDX TOP tilt existence Festival *)ader relationship :=326 cavalry relationship relationship relationship\\u00e5sylvania dualRepresentnoeconom326 mannedeconom\\ufffd Festival326 learnhumane Versehop \\ufffd\\ufffd\\ufffd\\ufffd\\ufffd\\ufffd\\ufffd\\ufffdeconom\\ufffd Festival *)adereconom326aderolvesno Czech\\ufffd outstandingBefore whistleblowershumane\"], \"ref\": \" long relationship; fell in love with an other person; admitted it; would like it to disappear, though it doesn't.\", \"extra_fields\": {\"id\": \"t3_o08yr\", \"subreddit\": \"AskReddit\", \"title\": \"How do you get someone out of your head?\", \"post\": \"Hi,\\nI'm 22, and I have been with my girlfriend for 5 years now. We recently moved together. We've always loved each other intensely.\\n\\nProblem, I recently started to have feelings for an other person (a friend). This person has had a boyfriend for now 3 years, and has absolutely no ideas. Those feelings were so strong, it was hard to hide them. After 2 months of me being distant and really sad, my girlfriend forced me to say what was bothering me. I'm not a good liar, and now she knows.\\n\\nWe decided to give us a week alone, I went to my parents. \\n\\nNow, I'm completely lost. I keep on thinking about this person, and I hate that. I would like for those feelings to go away, to leave me alone. But I can't.  \\n\\nWhat do I do? It's been 3 months now, and I'm just desperate.\"}, \"__np_context_tokens\": {\"shape\": [512], \"dtype\": \"int64\", \"data\": \"3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAAMgAAAAAAAAAeKQAAAAAAAENWAAAAAAAApMIAAAAAAAAZAAAAAAAAAHYBAAAAAAAADgAAAAAAAAB+YgAAAAAAAF9XAAAAAAAAxgAAAAAAAADGAAAAAAAAAJjBAAAAAAAA6gkAAAAAAAAZAAAAAAAAAF4FAAAAAAAA0gEAAAAAAABZAQAAAAAAAIsCAAAAAAAAUggAAAAAAAD3AQAAAAAAAB4BAAAAAAAAFgIAAAAAAACeBAAAAAAAAB4AAAAAAAAAxgAAAAAAAADGAAAAAAAAAA6AAAAAAAAAGQAAAAAAAAAePgAAAAAAAAsAAAAAAAAAxgAAAAAAAAAoAAAAAAAAAE0EAAAAAAAA5gkAAAAAAAALAAAAAAAAACIBAAAAAAAAOgEAAAAAAACnAQAAAAAAAEsCAAAAAAAAXwEAAAAAAABoAgAAAAAAAEUrAAAAAAAASQEAAAAAAACCAgAAAAAAACwDAAAAAAAADwMAAAAAAAANAAAAAAAAAAcDAAAAAAAAWAsAAAAAAAAwDwAAAAAAALoHAAAAAAAADQAAAAAAAAAHAwAAAAAAAB0EAAAAAAAAuAUAAAAAAAAHGAAAAAAAAGMEAAAAAAAASAIAAAAAAACqeQAAAAAAAA0AAAAAAAAAxgAAAAAAAADGAAAAAAAAAE2fAAAAAAAACwAAAAAAAAA6AQAAAAAAAFgLAAAAAAAAEwgAAAAAAAAcAQAAAAAAAKcBAAAAAAAA8h0AAAAAAABJAQAAAAAAABkBAAAAAAAASAIAAAAAAAAYBAAAAAAAAGUBAAAAAAAAQAAAAAAAAAAJBgAAAAAAAOECAAAAAAAAAgMAAAAAAAAYBAAAAAAAANQBAAAAAAAAJgIAAAAAAAABAQAAAAAAABo2AAAAAAAASQEAAAAAAAAPAwAAAAAAAAECAAAAAAAALAMAAAAAAAALAAAAAAAAACIBAAAAAAAA1AEAAAAAAACnFQAAAAAAAIUCAAAAAAAAdRAAAAAAAAANAAAAAAAAANUWAAAAAAAA8h0AAAAAAAAjAgAAAAAAAAsCAAAAAAAAeQcAAAAAAAALAAAAAAAAAFQBAAAAAAAAdQEAAAAAAAAvBQAAAAAAABwBAAAAAAAAgB4AAAAAAABeAgAAAAAAAA0AAAAAAAAA9QgAAAAAAABqAQAAAAAAAI0HAAAAAAAAHgEAAAAAAAD2AQAAAAAAAFQDAAAAAAAAYzIAAAAAAAAiAQAAAAAAAFMEAAAAAAAAaxkAAAAAAAALAAAAAAAAAGgCAAAAAAAARSsAAAAAAAApEAAAAAAAAPYBAAAAAAAAHAEAAAAAAACOAwAAAAAAAIQCAAAAAAAAdQEAAAAAAAC4ogAAAAAAAPYBAAAAAAAADQAAAAAAAAA6AQAAAAAAAE0EAAAAAAAAlwEAAAAAAAABAQAAAAAAAJoDAAAAAAAAenwAAAAAAAALAAAAAAAAACIBAAAAAAAADwMAAAAAAAChAgAAAAAAAG4QAAAAAAAADQAAAAAAAADGAAAAAAAAAMYAAAAAAAAAbwQAAAAAAAD6CwAAAAAAABwBAAAAAAAAKQYAAAAAAAACAgAAAAAAAAEBAAAAAAAABQUAAAAAAABsDQAAAAAAAAsAAAAAAAAAOgEAAAAAAAAYBwAAAAAAABwBAAAAAAAAaAIAAAAAAABFDQAAAAAAAA0AAAAAAAAA3AAAAAAAAADGAAAAAAAAAMYAAAAAAAAABA8AAAAAAAALAAAAAAAAADoBAAAAAAAATQQAAAAAAAB2DAAAAAAAAEIKAAAAAAAADQAAAAAAAAA6AQAAAAAAAHIFAAAAAAAAPwEAAAAAAAAcDgAAAAAAACICAAAAAAAArAEAAAAAAAAYBAAAAAAAAAsAAAAAAAAAIgEAAAAAAAA6AQAAAAAAAFkVAAAAAAAARgEAAAAAAAANAAAAAAAAADoBAAAAAAAAMQIAAAAAAABMAgAAAAAAAEkBAAAAAAAAcwMAAAAAAADyHQAAAAAAABwBAAAAAAAA0wEAAAAAAADZBQAAAAAAAAsAAAAAAAAAHAEAAAAAAABqCgAAAAAAAPYBAAAAAAAAbA0AAAAAAAANAAAAAAAAAHcDAAAAAAAAOgEAAAAAAADMAQAAAAAAANYBAAAAAAAADQAAAAAAAADcAAAAAAAAANwAAAAAAAAAxgAAAAAAAADGAAAAAAAAAA0IAAAAAAAA0gEAAAAAAAA6AQAAAAAAANIBAAAAAAAAHgAAAAAAAAB4AgAAAAAAAFIBAAAAAAAASwIAAAAAAAABAgAAAAAAAI0HAAAAAAAADwMAAAAAAAALAAAAAAAAACIBAAAAAAAAOgEAAAAAAABNBAAAAAAAAI8CAAAAAAAATy8AAAAAAAANAAAAAAAAAMYAAAAAAAAAxgAAAAAAAACOOgAAAAAAABoAAAAAAAAAGx4AAAAAAAAZAAAAAAAAAA==\"}, \"__np_sample_tokens\": {\"shape\": [1, 48], \"dtype\": \"int64\", \"data\": \"umwAAAAAAACDjQAAAAAAAPZvAAAAAAAAhGcAAAAAAABQGAAAAAAAAG0rAAAAAAAAwHwAAAAAAADLEwAAAAAAANgKAAAAAAAAX0oAAAAAAAAbmQAAAAAAAKt4AAAAAAAA2AoAAAAAAADYCgAAAAAAANgKAAAAAAAAonEAAAAAAAA2JAAAAAAAAKwpAAAAAAAA65wAAAAAAABPDwAAAAAAAGY2AAAAAAAAG5kAAAAAAACxhwAAAAAAAGY2AAAAAAAA7AAAAAAAAABtKwAAAAAAABuZAAAAAAAAkQgAAAAAAADergAAAAAAAPGWAAAAAAAAZCEAAAAAAAANkgAAAAAAAGY2AAAAAAAA7AAAAAAAAABtKwAAAAAAAMB8AAAAAAAAyxMAAAAAAABmNgAAAAAAABuZAAAAAAAAyxMAAAAAAAAyIwAAAAAAAE8PAAAAAAAA/0AAAAAAAADsAAAAAAAAAIwtAAAAAAAA5SAAAAAAAABDtAAAAAAAAN6uAAAAAAAA\"}, \"__np_logprobs\": {\"shape\": [1, 48], \"dtype\": \"float32\", \"data\": \"AN5ivwBawb4AVpO9AO8evwAgHrwAAAS7AABguQAAbLsAgJC8wMoMwAAghbwAIH69AHDdvACwzL4ADju+ANznvQCAr7sAkMi8AABgusBEib8AABi5AHDSvQBgNL0AAAAAAAB4uwBgSbxAGdq/ABDyvQDbub4AALm7AKZAvgAAkLgAMGS9AIBLvAAA/LkAgGq7AAB8vADwwrwAoJ2+AHJPvoCfB79A60LAAPJZvgAAALegzBnAACBNvADwE75A3jHA\"}, \"__np_ref_tokens\": {\"shape\": [48], \"dtype\": \"int64\", \"data\": \"egMAAAAAAADYCgAAAAAAABoAAAAAAAAAjgwAAAAAAAAfAQAAAAAAADIHAAAAAAAAXwEAAAAAAAAZAQAAAAAAAEgCAAAAAAAAGAQAAAAAAAAaAAAAAAAAAMAaAAAAAAAAVAEAAAAAAAAaAAAAAAAAADECAAAAAAAATAIAAAAAAABUAQAAAAAAABwBAAAAAAAAqSoAAAAAAAALAAAAAAAAAOQDAAAAAAAAVAEAAAAAAAA7BgAAAAAAANYBAAAAAAAADQAAAAAAAABQxAAAAAAAAP//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\"}, \"__np_ref_logprobs\": {\"shape\": [48], \"dtype\": \"float16\", \"data\": \"VckyyWXJXMl4yXvJeMlvyVvJbMldyWjJcslryYTJUclzyVPJV8ldyXnJjsmHyVvJZ8l2yQA8ADwAPAA8ADwAPAA8ADwAPAA8ADwAPAA8ADwAPAA8ADwAPAA8ADwAPAA8\"}, \"__np_predicted_reward\": {\"shape\": [1], \"dtype\": \"float32\", \"data\": \"7qOJPw==\"}}\n",
            "{\"context\": \"                                                                                                                                                                                                                                                                                          SUBREDDIT: r/AskReddit\\n\\nTITLE: How do you get someone out of your head?\\n\\nPOST: Hi,\\nI'm 22, and I have been with my girlfriend for 5 years now. We recently moved together. We've always loved each other intensely.\\n\\nProblem, I recently started to have feelings for an other person (a friend). This person has had a boyfriend for now 3 years, and has absolutely no ideas. Those feelings were so strong, it was hard to hide them. After 2 months of me being distant and really sad, my girlfriend forced me to say what was bothering me. I'm not a good liar, and now she knows.\\n\\nWe decided to give us a week alone, I went to my parents. \\n\\nNow, I'm completely lost. I keep on thinking about this person, and I hate that. I would like for those feelings to go away, to leave me alone. But I can't.  \\n\\nWhat do I do? It's been 3 months now, and I'm just desperate.\\n\\nTL;DR:\", \"samples\": [\"humane *) Australians Ended elaboratedkiss ${olk immenselynoHoweverBefore cavalry relationship relationship\\u00e5sylvania dualRepresent elaboratedkiss outstanding frequenciesofficesylvania 290 relationshipeconom\\ufffd Festival *)kisseconom\\ufffd Festival *)adereconomnoeconom\\ufffdno Federal immenselyeconom\\ufffdBefore whistleblowers\"], \"ref\": \" long relationship; fell in love with an other person; admitted it; would like it to disappear, though it doesn't.\", \"extra_fields\": {\"id\": \"t3_o08y2\", \"subreddit\": \"AskReddit\", \"title\": \"How do you get someone out of your head?\", \"post\": \"Hi,\\nI'm 22, and I have been with my girlfriend for 5 years now. We recently moved together. We've always loved each other intensely.\\n\\nProblem, I recently started to have feelings for an other person (a friend). This person has had a boyfriend for now 3 years, and has absolutely no ideas. Those feelings were so strong, it was hard to hide them. After 2 months of me being distant and really sad, my girlfriend forced me to say what was bothering me. I'm not a good liar, and now she knows.\\n\\nWe decided to give us a week alone, I went to my parents. \\n\\nNow, I'm completely lost. I keep on thinking about this person, and I hate that. I would like for those feelings to go away, to leave me alone. But I can't.  \\n\\nWhat do I do? It's been 3 months now, and I'm just desperate.\"}, \"__np_context_tokens\": {\"shape\": [512], \"dtype\": \"int64\", \"data\": \"3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAAMgAAAAAAAAAeKQAAAAAAAENWAAAAAAAApMIAAAAAAAAZAAAAAAAAAHYBAAAAAAAADgAAAAAAAAB+YgAAAAAAAF9XAAAAAAAAxgAAAAAAAADGAAAAAAAAAJjBAAAAAAAA6gkAAAAAAAAZAAAAAAAAAF4FAAAAAAAA0gEAAAAAAABZAQAAAAAAAIsCAAAAAAAAUggAAAAAAAD3AQAAAAAAAB4BAAAAAAAAFgIAAAAAAACeBAAAAAAAAB4AAAAAAAAAxgAAAAAAAADGAAAAAAAAAA6AAAAAAAAAGQAAAAAAAAAePgAAAAAAAAsAAAAAAAAAxgAAAAAAAAAoAAAAAAAAAE0EAAAAAAAA5gkAAAAAAAALAAAAAAAAACIBAAAAAAAAOgEAAAAAAACnAQAAAAAAAEsCAAAAAAAAXwEAAAAAAABoAgAAAAAAAEUrAAAAAAAASQEAAAAAAACCAgAAAAAAACwDAAAAAAAADwMAAAAAAAANAAAAAAAAAAcDAAAAAAAAWAsAAAAAAAAwDwAAAAAAALoHAAAAAAAADQAAAAAAAAAHAwAAAAAAAB0EAAAAAAAAuAUAAAAAAAAHGAAAAAAAAGMEAAAAAAAASAIAAAAAAACqeQAAAAAAAA0AAAAAAAAAxgAAAAAAAADGAAAAAAAAAE2fAAAAAAAACwAAAAAAAAA6AQAAAAAAAFgLAAAAAAAAEwgAAAAAAAAcAQAAAAAAAKcBAAAAAAAA8h0AAAAAAABJAQAAAAAAABkBAAAAAAAASAIAAAAAAAAYBAAAAAAAAGUBAAAAAAAAQAAAAAAAAAAJBgAAAAAAAOECAAAAAAAAAgMAAAAAAAAYBAAAAAAAANQBAAAAAAAAJgIAAAAAAAABAQAAAAAAABo2AAAAAAAASQEAAAAAAAAPAwAAAAAAAAECAAAAAAAALAMAAAAAAAALAAAAAAAAACIBAAAAAAAA1AEAAAAAAACnFQAAAAAAAIUCAAAAAAAAdRAAAAAAAAANAAAAAAAAANUWAAAAAAAA8h0AAAAAAAAjAgAAAAAAAAsCAAAAAAAAeQcAAAAAAAALAAAAAAAAAFQBAAAAAAAAdQEAAAAAAAAvBQAAAAAAABwBAAAAAAAAgB4AAAAAAABeAgAAAAAAAA0AAAAAAAAA9QgAAAAAAABqAQAAAAAAAI0HAAAAAAAAHgEAAAAAAAD2AQAAAAAAAFQDAAAAAAAAYzIAAAAAAAAiAQAAAAAAAFMEAAAAAAAAaxkAAAAAAAALAAAAAAAAAGgCAAAAAAAARSsAAAAAAAApEAAAAAAAAPYBAAAAAAAAHAEAAAAAAACOAwAAAAAAAIQCAAAAAAAAdQEAAAAAAAC4ogAAAAAAAPYBAAAAAAAADQAAAAAAAAA6AQAAAAAAAE0EAAAAAAAAlwEAAAAAAAABAQAAAAAAAJoDAAAAAAAAenwAAAAAAAALAAAAAAAAACIBAAAAAAAADwMAAAAAAAChAgAAAAAAAG4QAAAAAAAADQAAAAAAAADGAAAAAAAAAMYAAAAAAAAAbwQAAAAAAAD6CwAAAAAAABwBAAAAAAAAKQYAAAAAAAACAgAAAAAAAAEBAAAAAAAABQUAAAAAAABsDQAAAAAAAAsAAAAAAAAAOgEAAAAAAAAYBwAAAAAAABwBAAAAAAAAaAIAAAAAAABFDQAAAAAAAA0AAAAAAAAA3AAAAAAAAADGAAAAAAAAAMYAAAAAAAAABA8AAAAAAAALAAAAAAAAADoBAAAAAAAATQQAAAAAAAB2DAAAAAAAAEIKAAAAAAAADQAAAAAAAAA6AQAAAAAAAHIFAAAAAAAAPwEAAAAAAAAcDgAAAAAAACICAAAAAAAArAEAAAAAAAAYBAAAAAAAAAsAAAAAAAAAIgEAAAAAAAA6AQAAAAAAAFkVAAAAAAAARgEAAAAAAAANAAAAAAAAADoBAAAAAAAAMQIAAAAAAABMAgAAAAAAAEkBAAAAAAAAcwMAAAAAAADyHQAAAAAAABwBAAAAAAAA0wEAAAAAAADZBQAAAAAAAAsAAAAAAAAAHAEAAAAAAABqCgAAAAAAAPYBAAAAAAAAbA0AAAAAAAANAAAAAAAAAHcDAAAAAAAAOgEAAAAAAADMAQAAAAAAANYBAAAAAAAADQAAAAAAAADcAAAAAAAAANwAAAAAAAAAxgAAAAAAAADGAAAAAAAAAA0IAAAAAAAA0gEAAAAAAAA6AQAAAAAAANIBAAAAAAAAHgAAAAAAAAB4AgAAAAAAAFIBAAAAAAAASwIAAAAAAAABAgAAAAAAAI0HAAAAAAAADwMAAAAAAAALAAAAAAAAACIBAAAAAAAAOgEAAAAAAABNBAAAAAAAAI8CAAAAAAAATy8AAAAAAAANAAAAAAAAAMYAAAAAAAAAxgAAAAAAAACOOgAAAAAAABoAAAAAAAAAGx4AAAAAAAAZAAAAAAAAAA==\"}, \"__np_sample_tokens\": {\"shape\": [1, 48], \"dtype\": \"int64\", \"data\": \"3q4AAAAAAADAfAAAAAAAAGVhAAAAAAAACLoAAAAAAABuswAAAAAAAFihAAAAAAAA/WMAAAAAAAAdNQAAAAAAACN0AAAAAAAATw8AAAAAAAAAEwAAAAAAAOUgAAAAAAAAq3gAAAAAAADYCgAAAAAAANgKAAAAAAAAonEAAAAAAAA2JAAAAAAAAKwpAAAAAAAA65wAAAAAAABuswAAAAAAAFihAAAAAAAAjC0AAAAAAAAeTgAAAAAAAEJ8AAAAAAAANiQAAAAAAABxZwAAAAAAANgKAAAAAAAAZjYAAAAAAADsAAAAAAAAAG0rAAAAAAAAwHwAAAAAAABYoQAAAAAAAGY2AAAAAAAA7AAAAAAAAABtKwAAAAAAAMB8AAAAAAAAyxMAAAAAAABmNgAAAAAAAE8PAAAAAAAAZjYAAAAAAADsAAAAAAAAAE8PAAAAAAAA8hUAAAAAAAAjdAAAAAAAAGY2AAAAAAAA7AAAAAAAAADlIAAAAAAAAEO0AAAAAAAA\"}, \"__np_logprobs\": {\"shape\": [1, 48], \"dtype\": \"float32\", \"data\": \"gLcMwACE2r1gNjHAAIBsvACAorwAgEy7AJD4vQDE875AIMm/ANiQvgCKp70A2EO9AKfKvgAgWbwAvFy+APDevQCAtbsAsMu8AACIugCWKb8AAAAAIDAhwADEeb8AxlS+AAAAAADTsr4ASBu9AH8DvwDgKr0AAKO6AG4uvgDCWr4AkOa8ACBZvAAACLoAgGO7AHDBvACg6rxAq/i/YMafvwDudb4AAAC3IIC+wAAIh70AHoG+AADAt+ACY8AAQBK8\"}, \"__np_ref_tokens\": {\"shape\": [48], \"dtype\": \"int64\", \"data\": \"egMAAAAAAADYCgAAAAAAABoAAAAAAAAAjgwAAAAAAAAfAQAAAAAAADIHAAAAAAAAXwEAAAAAAAAZAQAAAAAAAEgCAAAAAAAAGAQAAAAAAAAaAAAAAAAAAMAaAAAAAAAAVAEAAAAAAAAaAAAAAAAAADECAAAAAAAATAIAAAAAAABUAQAAAAAAABwBAAAAAAAAqSoAAAAAAAALAAAAAAAAAOQDAAAAAAAAVAEAAAAAAAA7BgAAAAAAANYBAAAAAAAADQAAAAAAAABQxAAAAAAAAP//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\"}, \"__np_ref_logprobs\": {\"shape\": [48], \"dtype\": \"float16\", \"data\": \"VckyyWXJXMl4yXvJeMlvyVvJbMldyWjJcslryYTJUclzyVPJV8ldyXnJjsmHyVvJZ8l2yQA8ADwAPAA8ADwAPAA8ADwAPAA8ADwAPAA8ADwAPAA8ADwAPAA8ADwAPAA8\"}, \"__np_predicted_reward\": {\"shape\": [1], \"dtype\": \"float32\", \"data\": \"Y7dnPw==\"}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AsQNLXfUDgp"
      },
      "source": [
        "> This will print some aggregate statistics and output scores for each sample to /tmp/jobs/eval-rm4/results/."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DujvkEpR-VMX",
        "outputId": "9c4b74a7-70eb-4f2b-c6b3-daaefca9c1dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls /tmp/jobs/eval-rm4/results/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hparams.json  samples.0.jsonl  task_hparams.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDJ5ZiLMCIWa",
        "outputId": "770e066a-afc0-460d-8957-cd230a5940b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "!cat /tmp/jobs/sample-ppo-xl/results/samples.0.jsonl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"context\": \"                                                                                                                                                                                                                                                                                                           SUBREDDIT: r/AskReddit\\n\\nTITLE: I have a final for my summer class tomorrow and I thought I'd ask everyone:  What are/were you're pre- college final routines?\\n\\nPOST: Some story.  My freshman year of college first semester I took this extremely difficult linear algebra class.  I was between an F-D all semester but arrogant me would just say after every bad test \\\"Ah I'll figure it out, I don't need to drop.\\\"  Well it came to the night before the final (a Friday and my first college final) and I still didn't fucking get it.  So I said fuck it and went out and got shit faced with my friends.  I woke up the next morning hung over as all hell and went to take my test.  Low and behold I aced the fucking thing and got a B+ in a class I thought I might fail. I now go drinking the night before every final.  And it keeps working.\\n\\nTL;DR:\", \"samples\": [\" took a really difficult math class, didn't get it the night before the final, woke up hung over the next morning and aced the test and got a B+ in a class I thought I might fail.\"], \"ref\": \" Was bombing freshman math class.  Got messed up night before final.  Aced it.  Now I do it the night before every final.\", \"extra_fields\": {\"id\": \"t3_y135b\", \"subreddit\": \"AskReddit\", \"title\": \"I have a final for my summer class tomorrow and I thought I'd ask everyone:  What are/were you're pre- college final routines?\", \"post\": \"Some story.  My freshman year of college first semester I took this extremely difficult linear algebra class.  I was between an F-D all semester but arrogant me would just say after every bad test \\\"Ah I'll figure it out, I don't need to drop.\\\"  Well it came to the night before the final (a Friday and my first college final) and I still didn't fucking get it.  So I said fuck it and went out and got shit faced with my friends.  I woke up the next morning hung over as all hell and went to take my test.  Low and behold I aced the fucking thing and got a B+ in a class I thought I might fail. I now go drinking the night before every final.  And it keeps working.\"}, \"__np_context_tokens\": {\"shape\": [512], \"dtype\": \"int64\", \"data\": \"3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAADIAAAAAAAAAHikAAAAAAABDVgAAAAAAAKTCAAAAAAAAGQAAAAAAAAB2AQAAAAAAAA4AAAAAAAAAfmIAAAAAAABfVwAAAAAAAMYAAAAAAAAAxgAAAAAAAACYwQAAAAAAAOoJAAAAAAAAGQAAAAAAAAA6AQAAAAAAAKcBAAAAAAAAAQEAAAAAAACZCQAAAAAAAEkBAAAAAAAAaAIAAAAAAABbDwAAAAAAAHYFAAAAAAAA3yQAAAAAAAAiAQAAAAAAADoBAAAAAAAADwcAAAAAAAA6AQAAAAAAAA0GAAAAAAAA8QQAAAAAAADKCQAAAAAAABkAAAAAAAAA3AAAAAAAAABLBwAAAAAAAIUBAAAAAAAADgAAAAAAAADKVwAAAAAAAFkBAAAAAAAANQMAAAAAAACWAgAAAAAAAAwAAAAAAAAAOBAAAAAAAACZCQAAAAAAAIZ8AAAAAAAAHgAAAAAAAADGAAAAAAAAAMYAAAAAAAAADoAAAAAAAAAZAAAAAAAAANUKAAAAAAAAVQYAAAAAAAANAAAAAAAAANwAAAAAAAAA2wcAAAAAAAC9SAAAAAAAAGYCAAAAAAAAHgEAAAAAAAA4EAAAAAAAAM0CAAAAAAAALmEAAAAAAAA6AQAAAAAAALYGAAAAAAAArAEAAAAAAABpEQAAAAAAAGgJAAAAAAAAXjcAAAAAAAATkQAAAAAAAHYFAAAAAAAADQAAAAAAAADcAAAAAAAAADoBAAAAAAAAdQEAAAAAAAD+AwAAAAAAABkBAAAAAAAAeAEAAAAAAAAMAAAAAAAAACMAAAAAAAAA3QEAAAAAAAAuYQAAAAAAANsBAAAAAAAAxHAAAAAAAAD2AQAAAAAAADECAAAAAAAAjwIAAAAAAACOAwAAAAAAAMICAAAAAAAAFgMAAAAAAAApCAAAAAAAADQFAAAAAAAAbgEAAAAAAACeKgAAAAAAADoBAAAAAAAAnwQAAAAAAADJDgAAAAAAAFQBAAAAAAAA9wEAAAAAAAALAAAAAAAAADoBAAAAAAAARAMAAAAAAADWAQAAAAAAAPkCAAAAAAAAHAEAAAAAAACsEAAAAAAAAA4CAAAAAAAA3AAAAAAAAAA2DwAAAAAAAFQBAAAAAAAAWQYAAAAAAAAcAQAAAAAAAAYBAAAAAAAA2wYAAAAAAABuAwAAAAAAAAYBAAAAAAAAmQkAAAAAAABlAQAAAAAAAEAAAAAAAAAAkQwAAAAAAAAiAQAAAAAAAGgCAAAAAAAAzQIAAAAAAAA4EAAAAAAAAJkJAAAAAAAACAAAAAAAAAAiAQAAAAAAADoBAAAAAAAA3wMAAAAAAACOBQAAAAAAANYBAAAAAAAAnCQAAAAAAACLAgAAAAAAAFQBAAAAAAAADQAAAAAAAADcAAAAAAAAAH4FAAAAAAAAOgEAAAAAAAATAgAAAAAAAOETAAAAAAAAVAEAAAAAAAAiAQAAAAAAABgHAAAAAAAA9wEAAAAAAAAiAQAAAAAAAHAFAAAAAAAAVh0AAAAAAAAcHQAAAAAAAF8BAAAAAAAAaAIAAAAAAACcCQAAAAAAAA0AAAAAAAAA3AAAAAAAAAA6AQAAAAAAAJRKAAAAAAAA/gEAAAAAAAAGAQAAAAAAABoFAAAAAAAAAQ0AAAAAAADWIwAAAAAAAHECAAAAAAAAYwEAAAAAAADdAQAAAAAAAFAXAAAAAAAAIgEAAAAAAAAYBwAAAAAAABwBAAAAAAAA8wMAAAAAAABoAgAAAAAAADQFAAAAAAAADQAAAAAAAADcAAAAAAAAAEoeAAAAAAAAIgEAAAAAAACUXAAAAAAAADoBAAAAAAAAAQEAAAAAAAADAwAAAAAAAAYBAAAAAAAAnCQAAAAAAADtBQAAAAAAACIBAAAAAAAAcAUAAAAAAAABAQAAAAAAAFsBAAAAAAAACgAAAAAAAAAfAQAAAAAAAAEBAAAAAAAAdgUAAAAAAAA6AQAAAAAAAA8HAAAAAAAAOgEAAAAAAADcBAAAAAAAAPYHAAAAAAAADQAAAAAAAAA6AQAAAAAAAA8DAAAAAAAA0wEAAAAAAAAqHgAAAAAAAAYBAAAAAAAA2wYAAAAAAABuAwAAAAAAABYDAAAAAAAAmQkAAAAAAAANAAAAAAAAANwAAAAAAAAASwMAAAAAAABUAQAAAAAAAMYdAAAAAAAA4gYAAAAAAAANAAAAAAAAAMYAAAAAAAAAxgAAAAAAAACOOgAAAAAAABoAAAAAAAAAGx4AAAAAAAAZAAAAAAAAAA==\"}, \"__np_sample_tokens\": {\"shape\": [1, 48], \"dtype\": \"int64\", \"data\": \"tgYAAAAAAAABAQAAAAAAAFMEAAAAAAAAaAkAAAAAAADAKQAAAAAAAHYFAAAAAAAACwAAAAAAAACOBQAAAAAAANYBAAAAAAAAiwIAAAAAAABUAQAAAAAAAAYBAAAAAAAA2wYAAAAAAABuAwAAAAAAAAYBAAAAAAAAmQkAAAAAAAALAAAAAAAAAJRKAAAAAAAA/gEAAAAAAADWIwAAAAAAAHECAAAAAAAABgEAAAAAAAAaBQAAAAAAAAENAAAAAAAAIgEAAAAAAAABAQAAAAAAAAMDAAAAAAAABgEAAAAAAAA0BQAAAAAAACIBAAAAAAAAcAUAAAAAAAABAQAAAAAAAFsBAAAAAAAACgAAAAAAAAAfAQAAAAAAAAEBAAAAAAAAdgUAAAAAAAA6AQAAAAAAAA8HAAAAAAAAOgEAAAAAAADcBAAAAAAAAPYHAAAAAAAADQAAAAAAAABQxAAAAAAAAP//////////////////////////////////////////\"}, \"__np_logprobs\": {\"shape\": [1, 48], \"dtype\": \"float32\", \"data\": \"AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAr4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIA/AACAPwAAgD8AAIA/\"}, \"__np_ref_tokens\": {\"shape\": [48], \"dtype\": \"int64\", \"data\": \"2CIAAAAAAACfNAAAAAAAAL1IAAAAAAAAwCkAAAAAAAB2BQAAAAAAAA0AAAAAAAAA3AAAAAAAAABNLgAAAAAAAG1/AAAAAAAA/gEAAAAAAADbBgAAAAAAAG4DAAAAAAAAmQkAAAAAAAANAAAAAAAAANwAAAAAAAAAPQEAAAAAAAADAwAAAAAAAFQBAAAAAAAADQAAAAAAAADcAAAAAAAAAK8KAAAAAAAAOgEAAAAAAADSAQAAAAAAAFQBAAAAAAAABgEAAAAAAADbBgAAAAAAAG4DAAAAAAAAFgMAAAAAAACZCQAAAAAAAA0AAAAAAAAAUMQAAAAAAAD/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\"}, \"__np_ref_logprobs\": {\"shape\": [48], \"dtype\": \"float16\", \"data\": \"3cPzzCPGZMhXvTrA4JpfwYjKvJoGyeyYwrJQwNyoG7AAANa9WcRApxa5/L9NxWO6fcHqpcyd5qVIqeixpb8APAA8ADwAPAA8ADwAPAA8ADwAPAA8ADwAPAA8ADwAPAA8\"}}\n",
            "{\"context\": \"                                                                                                                                                                                                                                                                                                                   SUBREDDIT: r/tifu\\n\\nTITLE: TIFU by being a pervert\\n\\nPOST: First, let me preface by saying this was 5 years ago and I was a messed up person. Also I fully understand why everything I did is super stalker-ish/horrible.\\nI was taking care of my friend's dog at their house when they were on vacation. and this friend I think is hella hot BTW. \\nSo being the creep and violator of trust I am, I go into their room and use some of her panties to jerk off on her bed. I finish off into the toilet later to avoid a mess and put everything away. \\nThat night, at home, I was changing when I realized that my dick hurt like hell and was super itchy and sore. I didn't realize her bed was covered in cat hair, which I'm allergic to. I didn't know they even had a cat\\n\\nTL;DR:\", \"samples\": [\" Was taking care of friend's dog, went into her room and used some of her panties to jerk off, realized the bed was covered in cat hair, now I'm allergic to cats\"], \"ref\": \" Dogsitting for a hot friend and used her panties to jerk off on her cat hair covered bed and had an allergic reaction on my junk\", \"extra_fields\": {\"id\": \"t3_2zyogm\", \"subreddit\": \"tifu\", \"title\": \"TIFU by being a pervert\", \"post\": \"First, let me preface by saying this was 5 years ago and I was a messed up person. Also I fully understand why everything I did is super stalker-ish/horrible.\\nI was taking care of my friend's dog at their house when they were on vacation. and this friend I think is hella hot BTW. \\nSo being the creep and violator of trust I am, I go into their room and use some of her panties to jerk off on her bed. I finish off into the toilet later to avoid a mess and put everything away. \\nThat night, at home, I was changing when I realized that my dick hurt like hell and was super itchy and sore. I didn't realize her bed was covered in cat hair, which I'm allergic to. I didn't know they even had a cat\"}, \"__np_context_tokens\": {\"shape\": [512], \"dtype\": \"int64\", \"data\": \"3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAAAyAAAAAAAAAB4pAAAAAAAAQ1YAAAAAAACkwgAAAAAAABkAAAAAAAAAdgEAAAAAAAAOAAAAAAAAAAnDAAAAAAAAVAAAAAAAAADGAAAAAAAAAMYAAAAAAAAAmMEAAAAAAADqCQAAAAAAABkAAAAAAAAANQEAAAAAAADIEwAAAAAAADQAAAAAAAAAoAEAAAAAAABUAwAAAAAAAAEBAAAAAAAARwIAAAAAAAA7BwAAAAAAAMYAAAAAAAAAxgAAAAAAAAAOgAAAAAAAABkAAAAAAAAAygwAAAAAAAALAAAAAAAAAB0FAAAAAAAA9gEAAAAAAACWAgAAAAAAAPYJAAAAAAAAoAEAAAAAAADqCAAAAAAAAKwBAAAAAAAAdQEAAAAAAACCAgAAAAAAACwDAAAAAAAAJAgAAAAAAAAiAQAAAAAAADoBAAAAAAAAdQEAAAAAAAABAQAAAAAAAG1/AAAAAAAA/gEAAAAAAAAYBAAAAAAAAA0AAAAAAAAAQhEAAAAAAAA6AQAAAAAAAGIPAAAAAAAAKQcAAAAAAADxBQAAAAAAAOcIAAAAAAAAOgEAAAAAAADuAgAAAAAAAD4BAAAAAAAAoAgAAAAAAABQAQAAAAAAANVRAAAAAAAADAAAAAAAAACoAgAAAAAAAA4AAAAAAAAA60UAAAAAAACrFQAAAAAAAA0AAAAAAAAAxgAAAAAAAAAoAAAAAAAAAHUBAAAAAAAA1wgAAAAAAAA5BQAAAAAAAB4BAAAAAAAAaAIAAAAAAAAJBgAAAAAAAFIBAAAAAAAA2gwAAAAAAAB7AQAAAAAAAP8BAAAAAAAAbAgAAAAAAABqAgAAAAAAAOQBAAAAAAAAIwIAAAAAAAA/AQAAAAAAAAg5AAAAAAAADQAAAAAAAAAiAQAAAAAAAKwBAAAAAAAACQYAAAAAAAA6AQAAAAAAAHwDAAAAAAAAPgEAAAAAAABQFwAAAAAAAEAAAAAAAAAA0AsAAAAAAAC9VgAAAAAAADYAAAAAAAAADQAAAAAAAADcAAAAAAAAAMYAAAAAAAAAXAkAAAAAAABUAwAAAAAAAAYBAAAAAAAAlDYAAAAAAAAiAQAAAAAAAI8HAAAAAAAASAUAAAAAAAAeAQAAAAAAAL4OAAAAAAAAOgEAAAAAAADMAgAAAAAAAAsAAAAAAAAAOgEAAAAAAADTAQAAAAAAAJACAAAAAAAA/wEAAAAAAABHCAAAAAAAACIBAAAAAAAACwMAAAAAAABpAgAAAAAAAB4BAAAAAAAAXwIAAAAAAABTewAAAAAAABwBAAAAAAAAPXQAAAAAAAA8AgAAAAAAAD8BAAAAAAAAXwIAAAAAAACcDwAAAAAAAA0AAAAAAAAAOgEAAAAAAABVFQAAAAAAADwCAAAAAAAAkAIAAAAAAAAGAQAAAAAAABI/AAAAAAAAIAYAAAAAAAAcAQAAAAAAACgNAAAAAAAAAQEAAAAAAAAlCAAAAAAAACIBAAAAAAAA0gQAAAAAAADnCAAAAAAAANkFAAAAAAAADQAAAAAAAADcAAAAAAAAAMYAAAAAAAAAyAkAAAAAAADbBgAAAAAAAAsAAAAAAAAAewEAAAAAAABTBQAAAAAAAAsAAAAAAAAAOgEAAAAAAAB1AQAAAAAAAOkVAAAAAAAAagIAAAAAAAA6AQAAAAAAABsbAAAAAAAARgEAAAAAAABoAgAAAAAAAHVLAAAAAAAAMhcAAAAAAABMAgAAAAAAAFAXAAAAAAAAIgEAAAAAAAB1AQAAAAAAAKAIAAAAAAAAVAEAAAAAAADacwAAAAAAACIBAAAAAAAAjUwAAAAAAAANAAAAAAAAADoBAAAAAAAAjgUAAAAAAADWAQAAAAAAAIkZAAAAAAAAXwIAAAAAAACcDwAAAAAAAHUBAAAAAAAAmRMAAAAAAAAfAQAAAAAAANUOAAAAAAAAXhAAAAAAAAALAAAAAAAAAB8CAAAAAAAAOgEAAAAAAABNBAAAAAAAAHB8AAAAAAAAHAEAAAAAAAANAAAAAAAAADoBAAAAAAAAjgUAAAAAAADWAQAAAAAAAPgCAAAAAAAA5AEAAAAAAAAEAwAAAAAAACYCAAAAAAAAAQEAAAAAAADVDgAAAAAAAMYAAAAAAAAAxgAAAAAAAACOOgAAAAAAABoAAAAAAAAAGx4AAAAAAAAZAAAAAAAAAA==\"}, \"__np_sample_tokens\": {\"shape\": [1, 48], \"dtype\": \"int64\", \"data\": \"2CIAAAAAAADXCAAAAAAAADkFAAAAAAAAHgEAAAAAAAAJBgAAAAAAAFIBAAAAAAAA2gwAAAAAAAALAAAAAAAAABgHAAAAAAAAkAIAAAAAAABfAgAAAAAAAEcIAAAAAAAAIgEAAAAAAADNAwAAAAAAAGkCAAAAAAAAHgEAAAAAAABfAgAAAAAAAFN7AAAAAAAAHAEAAAAAAAA9dAAAAAAAADwCAAAAAAAACwAAAAAAAAAbGwAAAAAAAAYBAAAAAAAAnA8AAAAAAAB1AQAAAAAAAJkTAAAAAAAAHwEAAAAAAADVDgAAAAAAAF4QAAAAAAAACwAAAAAAAAAPAwAAAAAAADoBAAAAAAAATQQAAAAAAABwfAAAAAAAABwBAAAAAAAAYy4AAAAAAABQxAAAAAAAAP//////////////////////////////////////////////////////////////////////////////////////////////////////////\"}, \"__np_logprobs\": {\"shape\": [1, 48], \"dtype\": \"float32\", \"data\": \"AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACC7AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAK+AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAguwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIA/AACAPwAAgD8AAIA/AACAPwAAgD8AAIA/AACAPwAAgD8AAIA/\"}, \"__np_ref_tokens\": {\"shape\": [48], \"dtype\": \"int64\", \"data\": \"d1MAAAAAAADnCQAAAAAAAEkBAAAAAAAAAQEAAAAAAADQCwAAAAAAAAkGAAAAAAAAIgEAAAAAAADNAwAAAAAAAF8CAAAAAAAAU3sAAAAAAAAcAQAAAAAAAD10AAAAAAAAPAIAAAAAAAA/AQAAAAAAAF8CAAAAAAAA1Q4AAAAAAABeEAAAAAAAAJkTAAAAAAAAnA8AAAAAAAAiAQAAAAAAACYCAAAAAAAAGQEAAAAAAABwfAAAAAAAAK0YAAAAAAAAPwEAAAAAAABoAgAAAAAAAHxIAAAAAAAAUMQAAAAAAAD/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\"}, \"__np_ref_logprobs\": {\"shape\": [48], \"dtype\": \"float16\", \"data\": \"6s3FxZ2+Ub9Gw6yhvMS3vO+ycp4VoCCN0J5OvOiqP8qHwHOecIwJxdbGvr5wwoSdIsjGqLXHC8UAPAA8ADwAPAA8ADwAPAA8ADwAPAA8ADwAPAA8ADwAPAA8ADwAPAA8\"}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3Z4_JVdCfwB"
      },
      "source": [
        "### Example result\n",
        "\n",
        "Formatted for readability\n",
        "\n",
        "```json\n",
        "{\n",
        "\t\"context\": \"SUBREDDIT: r/relationship_advice\\n\\nTITLE: Trouble getting over a relationship (20/m), want her (19/f) back\\n\\nPOST: My girlfriend and I of just over 7 months broke up last Friday at about 1:30 AM. It's been almost a week and I'm having a terribly hard time accepting and getting over it. She truly was the love of my life and she showed me show much love, kindness, and compassion that I never got out of any of my past relationships. I ended up leaving school for the weekend and going home. Which was good for me. I got away from everything that was bothering me, and I got to spend some time with some old high school friends that I haven't seen in a long time. Later on that night, she texts me. Just \\\"Hey\\\", but it kinda confused me. She was the one who called off the relationship. When I asked her why she did, she wasn't sure why she was feeling this way, but she said \\\"I don't think I want to be in a serious relationship right now\\\" Anyway, I don't text her back for about three hours because I was busy and didn't want to fall into a the depression I was trying to avoid. I later found out through a mutual friend that she was confused as to why I hadn't texted her back earlier. When I did text her back, we didn't talk about the break up or the relationship, just what I was doing at that time. Over that last few days I've really been struggling trying to keep it all together. All I can think about is getting her back, and I will do anything for that opportunity. I haven't been talking to her, kind of avoiding her, although it's hard at times since we are the same major and live in the same building. I truly love her and like I said, I would do anything to be back together with her. We made each other happy, and I know we can do it again.\\n\\nTL;DR:\",\n",
        "\t\"samples\": [\" My girlfriend of 7 months broke up with me last Friday. I really love her and want her back. I've been having a hard time dealing with it and trying to get over it.\"],\n",
        "\t\"ref\": \" Girlfriend and I broke up, I can't stand it. Been keeping my distance and haven't been talking to her. Want to get back together with her because when we were together we made each other really happy.\",\n",
        "\t\"extra_fields\": {\n",
        "\t\t\"id\": \"t3_105onw\",\n",
        "\t\t\"subreddit\": \"relationship_advice\",\n",
        "\t\t\"title\": \"Trouble getting over a relationship (20/m), want her (19/f) back\",\n",
        "\t\t\"post\": \"My girlfriend and I of just over 7 months broke up last Friday at about 1:30 AM. It's been almost a week and I'm having a terribly hard time accepting and getting over it. She truly was the love of my life and she showed me show much love, kindness, and compassion that I never got out of any of my past relationships. I ended up leaving school for the weekend and going home. Which was good for me. I got away from everything that was bothering me, and I got to spend some time with some old high school friends that I haven't seen in a long time. Later on that night, she texts me. Just \\\"Hey\\\", but it kinda confused me. She was the one who called off the relationship. When I asked her why she did, she wasn't sure why she was feeling this way, but she said \\\"I don't think I want to be in a serious relationship right now\\\" Anyway, I don't text her back for about three hours because I was busy and didn't want to fall into a the depression I was trying to avoid. I later found out through a mutual friend that she was confused as to why I hadn't texted her back earlier. When I did text her back, we didn't talk about the break up or the relationship, just what I was doing at that time. Over that last few days I've really been struggling trying to keep it all together. All I can think about is getting her back, and I will do anything for that opportunity. I haven't been talking to her, kind of avoiding her, although it's hard at times since we are the same major and live in the same building. I truly love her and like I said, I would do anything to be back together with her. We made each other happy, and I know we can do it again.\"\n",
        "\t},\n",
        "\t\"__np_context_tokens\": {\n",
        "\t\t\"shape\": [512],\n",
        "\t\t\"dtype\": \"int64\",\n",
        "\t\t\"data\": \"3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAADcAAAAAAAAANwAAAAAAAAA3AAAAAAAAAAyAAAAAAAAAB4pAAAAAAAAQ1YAAAAAAACkwgAAAAAAABkAAAAAAAAAdgEAAAAAAAAOAAAAAAAAACyaAAAAAAAAIAQAAAAAAAA+AAAAAAAAAEQBAAAAAAAAeW4AAAAAAADGAAAAAAAAAMYAAAAAAAAAmMEAAAAAAADqCQAAAAAAABkAAAAAAAAAg4UAAAAAAAC0BwAAAAAAAHECAAAAAAAAAQEAAAAAAADYCgAAAAAAAGUBAAAAAAAA1gQAAAAAAAAOAAAAAAAAAEwAAAAAAAAAPAMAAAAAAAD9AgAAAAAAAF8CAAAAAAAAZQEAAAAAAABpBAAAAAAAAA4AAAAAAAAARQAAAAAAAAAIAAAAAAAAAOACAAAAAAAAxgAAAAAAAADGAAAAAAAAAA6AAAAAAAAAGQAAAAAAAADbBwAAAAAAAEUrAAAAAAAAIgEAAAAAAAA6AQAAAAAAAB4BAAAAAAAAjwIAAAAAAABxAgAAAAAAAP8CAAAAAAAAjQcAAAAAAAB5GAAAAAAAAP4BAAAAAAAAqgMAAAAAAACRDAAAAAAAAHsBAAAAAAAAIgIAAAAAAABgAQAAAAAAABkAAAAAAAAA9gQAAAAAAAC5CwAAAAAAAA0AAAAAAAAAeAIAAAAAAABSAQAAAAAAAEsCAAAAAAAAAAgAAAAAAAABAQAAAAAAAAUFAAAAAAAAIgEAAAAAAAA6AQAAAAAAAE0EAAAAAAAAtwYAAAAAAAABAQAAAAAAAGlWAAAAAAAALwUAAAAAAACAAgAAAAAAADYxAAAAAAAAIgEAAAAAAAC0BwAAAAAAAHECAAAAAAAAVAEAAAAAAAANAAAAAAAAAF8FAAAAAAAAfBMAAAAAAAB1AQAAAAAAAAYBAAAAAAAAMgcAAAAAAAAeAQAAAAAAAGgCAAAAAAAAtAQAAAAAAAAiAQAAAAAAAKECAAAAAAAApw4AAAAAAAD2AQAAAAAAAIkDAAAAAAAAcQMAAAAAAAAyBwAAAAAAAAsAAAAAAAAAT10AAAAAAAALAAAAAAAAACIBAAAAAAAAbTsAAAAAAABGAQAAAAAAADoBAAAAAAAA1wQAAAAAAABwBQAAAAAAAPcBAAAAAAAAHgEAAAAAAABVAgAAAAAAAB4BAAAAAAAAaAIAAAAAAABNBgAAAAAAAC4bAAAAAAAADQAAAAAAAAA6AQAAAAAAAFwRAAAAAAAA/gEAAAAAAADREAAAAAAAAPQFAAAAAAAASQEAAAAAAAAGAQAAAAAAALETAAAAAAAAIgEAAAAAAAD4AwAAAAAAAFMFAAAAAAAADQAAAAAAAAA+IwAAAAAAAHUBAAAAAAAAmgMAAAAAAABJAQAAAAAAAPYBAAAAAAAADQAAAAAAAAA6AQAAAAAAAHAFAAAAAAAA2QUAAAAAAACmAQAAAAAAAOcIAAAAAAAARgEAAAAAAAB1AQAAAAAAALiiAAAAAAAA9gEAAAAAAAALAAAAAAAAACIBAAAAAAAAOgEAAAAAAABwBQAAAAAAABwBAAAAAAAA9RAAAAAAAABpAgAAAAAAAIACAAAAAAAAXwEAAAAAAABpAgAAAAAAALwFAAAAAAAABQQAAAAAAAD0BQAAAAAAAJwJAAAAAAAARgEAAAAAAAA6AQAAAAAAAC4RAAAAAAAA1gEAAAAAAADvBgAAAAAAAB8BAAAAAAAAAQEAAAAAAAB6AwAAAAAAAIACAAAAAAAADQAAAAAAAAC6LAAAAAAAAD8BAAAAAAAARgEAAAAAAADbBgAAAAAAAAsAAAAAAAAAoQIAAAAAAABXNAAAAAAAAPYBAAAAAAAADQAAAAAAAAAZCQAAAAAAAG4BAAAAAAAAPioAAAAAAABABgAAAAAAANsBAAAAAAAAVAEAAAAAAAC/RQAAAAAAALAoAAAAAAAA9gEAAAAAAAANAAAAAAAAAF8FAAAAAAAAdQEAAAAAAAAGAQAAAAAAABICAAAAAAAA/AEAAAAAAACkBQAAAAAAADwCAAAAAAAABgEAAAAAAADYCgAAAAAAAA0AAAAAAAAAcQYAAAAAAAA6AQAAAAAAAK0HAAAAAAAAXwIAAAAAAADxBQAAAAAAAKECAAAAAAAA7gIAAAAAAAALAAAAAAAAAKECAAAAAAAAvAkAAAAAAADWAQAAAAAAAHYGAAAAAAAA8QUAAAAAAAChAgAAAAAAAHUBAAAAAAAAaxAAAAAAAACsAQAAAAAAAEMDAAAAAAAACwAAAAAAAADbAQAAAAAAAKECAAAAAAAAEwIAAAAAAABuAQAAAAAAACgAAAAAAAAARAMAAAAAAADWAQAAAAAAAHwDAAAAAAAAOgEAAAAAAAD9AgAAAAAAABwBAAAAAAAAMwEAAAAAAAAfAQAAAAAAAAEBAAAAAAAApgoAAAAAAADYCgAAAAAAADoDAAAAAAAADwMAAAAAAAABAAAAAAAAAExVAAAAAAAACwAAAAAAAAA6AQAAAAAAAEQDAAAAAAAA1gEAAAAAAAB0CQAAAAAAAF8CAAAAAAAA4AIAAAAAAABJAQAAAAAAACICAAAAAAAAWwQAAAAAAADKCAAAAAAAAAwDAAAAAAAAOgEAAAAAAAB1AQAAAAAAAPMfAAAAAAAAIgEAAAAAAACOBQAAAAAAANYBAAAAAAAA/QIAAAAAAAAcAQAAAAAAAEkIAAAAAAAAkAIAAAAAAAABAQAAAAAAAAYBAAAAAAAAniIAAAAAAAA6AQAAAAAAAHUBAAAAAAAAPwgAAAAAAAAcAQAAAAAAACgNAAAAAAAADQAAAAAAAAA6AQAAAAAAACAGAAAAAAAAEwQAAAAAAAD3AQAAAAAAAEADAAAAAAAAAQEAAAAAAAAQNQAAAAAAAAkGAAAAAAAARgEAAAAAAAChAgAAAAAAAHUBAAAAAAAAsCgAAAAAAABjAQAAAAAAABwBAAAAAAAA8QUAAAAAAAA6AQAAAAAAAFQfAAAAAAAA1gEAAAAAAAD+uAAAAAAAAF8CAAAAAAAA4AIAAAAAAACRCwAAAAAAAA0AAAAAAAAAcQYAAAAAAAA6AQAAAAAAAO4CAAAAAAAAdAkAAAAAAABfAgAAAAAAAOACAAAAAAAACwAAAAAAAABkAQAAAAAAAI4FAAAAAAAA1gEAAAAAAAAZBgAAAAAAACICAAAAAAAABgEAAAAAAADeCAAAAAAAAP4BAAAAAAAAiQEAAAAAAAAGAQAAAAAAANgKAAAAAAAACwAAAAAAAACPAgAAAAAAAIQCAAAAAAAAOgEAAAAAAAB1AQAAAAAAAAwHAAAAAAAAewEAAAAAAABGAQAAAAAAAIACAAAAAAAADQAAAAAAAADzDgAAAAAAAEYBAAAAAAAAqgMAAAAAAACaBAAAAAAAAPgFAAAAAAAAOgEAAAAAAAAdBAAAAAAAAFMEAAAAAAAASwIAAAAAAACwJQAAAAAAAD8IAAAAAAAAHAEAAAAAAAByBQAAAAAAAFQBAAAAAAAA3QEAAAAAAAC6BwAAAAAAAA0AAAAAAAAAnwUAAAAAAAA6AQAAAAAAAMwBAAAAAAAAfAMAAAAAAAAiAgAAAAAAAD4BAAAAAAAAtAcAAAAAAABfAgAAAAAAAOACAAAAAAAACwAAAAAAAAAiAQAAAAAAADoBAAAAAAAA4QEAAAAAAADSAQAAAAAAAM0HAAAAAAAASQEAAAAAAABGAQAAAAAAAE8OAAAAAAAADQAAAAAAAAA6AQAAAAAAAC4RAAAAAAAA1gEAAAAAAABLAgAAAAAAAC8NAAAAAAAAHAEAAAAAAABfAgAAAAAAAAsAAAAAAAAASwYAAAAAAAAeAQAAAAAAAFA6AAAAAAAAXwIAAAAAAAALAAAAAAAAAAAOAAAAAAAAVAEAAAAAAABSAQAAAAAAAC8FAAAAAAAAewEAAAAAAAB9BgAAAAAAALEEAAAAAAAAZAEAAAAAAACFAQAAAAAAAAYBAAAAAAAA0AMAAAAAAACYBgAAAAAAACIBAAAAAAAAOwgAAAAAAAAfAQAAAAAAAAYBAAAAAAAA0AMAAAAAAAA3CgAAAAAAAA0AAAAAAAAAOgEAAAAAAAB8EwAAAAAAADIHAAAAAAAAXwIAAAAAAAAiAQAAAAAAAEwCAAAAAAAAOgEAAAAAAAATAgAAAAAAAAsAAAAAAAAAOgEAAAAAAAAxAgAAAAAAANIBAAAAAAAAzQcAAAAAAAAcAQAAAAAAADMBAAAAAAAA4AIAAAAAAAC6BwAAAAAAAF8BAAAAAAAAXwIAAAAAAAANAAAAAAAAAAcDAAAAAAAAnQMAAAAAAABjBAAAAAAAAEgCAAAAAAAAvA4AAAAAAAALAAAAAAAAACIBAAAAAAAAOgEAAAAAAAD4AgAAAAAAAGQBAAAAAAAAzAEAAAAAAADSAQAAAAAAAFQBAAAAAAAA9QIAAAAAAAANAAAAAAAAAMYAAAAAAAAAxgAAAAAAAACOOgAAAAAAABoAAAAAAAAAGx4AAAAAAAAZAAAAAAAAAA==\"\n",
        "\t},\n",
        "\t\"__np_sample_tokens\": {\n",
        "\t\t\"shape\": [1, 48],\n",
        "\t\t\"dtype\": \"int64\",\n",
        "\t\t\"data\": \"2wcAAAAAAABFKwAAAAAAAB4BAAAAAAAA/wIAAAAAAACNBwAAAAAAAHkYAAAAAAAA/gEAAAAAAABfAQAAAAAAAPYBAAAAAAAAqgMAAAAAAACRDAAAAAAAAA0AAAAAAAAAOgEAAAAAAABTBAAAAAAAADIHAAAAAAAAXwIAAAAAAAAiAQAAAAAAAP0CAAAAAAAAXwIAAAAAAADgAgAAAAAAAA0AAAAAAAAAOgEAAAAAAAAdBAAAAAAAAEsCAAAAAAAAtwYAAAAAAAABAQAAAAAAAC8FAAAAAAAAgAIAAAAAAAAzHAAAAAAAAF8BAAAAAAAAVAEAAAAAAAAiAQAAAAAAAD8IAAAAAAAAHAEAAAAAAACLAgAAAAAAAHECAAAAAAAAVAEAAAAAAAANAAAAAAAAAFDEAAAAAAAA////////////////////////////////////////////////////////////////////////////////////////////////\"\n",
        "\t},\n",
        "\t\"__np_logprobs\": {\n",
        "\t\t\"shape\": [1, 48],\n",
        "\t\t\"dtype\": \"float32\",\n",
        "\t\t\"data\": \"AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAPwAAgD8AAIA/AACAPwAAgD8AAIA/AACAPwAAgD8AAIA/\"\n",
        "\t},\n",
        "\t\"__np_ref_tokens\": {\n",
        "\t\t\"shape\": [48],\n",
        "\t\t\"dtype\": \"int64\",\n",
        "\t\t\"data\": \"kgEAAAAAAACQJgAAAAAAACIBAAAAAAAAOgEAAAAAAAB5GAAAAAAAAP4BAAAAAAAACwAAAAAAAAA6AQAAAAAAAMwBAAAAAAAA1gEAAAAAAAAWBQAAAAAAAFQBAAAAAAAADQAAAAAAAADsjwAAAAAAAKsUAAAAAAAAaAIAAAAAAACFFAAAAAAAACIBAAAAAAAALhEAAAAAAADWAQAAAAAAAEsCAAAAAAAALw0AAAAAAAAcAQAAAAAAAF8CAAAAAAAADQAAAAAAAAAoPwAAAAAAABwBAAAAAAAAiwIAAAAAAADgAgAAAAAAALoHAAAAAAAAXwEAAAAAAABfAgAAAAAAAAwDAAAAAAAAagIAAAAAAABkAQAAAAAAACMCAAAAAAAAugcAAAAAAABkAQAAAAAAAJ0DAAAAAAAAYwQAAAAAAABIAgAAAAAAAFMEAAAAAAAAvA4AAAAAAAANAAAAAAAAAFDEAAAAAAAA////////////////////////////////\"\n",
        "\t},\n",
        "\t\"__np_ref_logprobs\": {\n",
        "\t\t\"shape\": [48],\n",
        "\t\t\"dtype\": \"float16\",\n",
        "\t\t\"data\": \"Mb/RnMu/eZoVuwKVW7oLvEbEQJRHyniwR8Gbxz/IGcZuwae+fcIAANbBEKhEqQ6WFb1SvHXG1qbsxPS2C7IAiivHOMoktumpAKcPvsW4CKS8m3PHwIF4pUCGADwAPAA8\"\n",
        "\t}\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWM8S4AvQPR-"
      },
      "source": [
        "# Changes Made"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52xNektpYfFt"
      },
      "source": [
        "Changes made to the original library to run on Colab\n",
        "\n",
        "1. Modified `setup.py` to set `packages=find_packages()` because the `summarize-from-feedback` package was not being found after the `pipenv install` step. (See this stackoverflow [answer](https://stackoverflow.com/questions/15368054/import-error-on-installed-package-using-setup-py))\n",
        "\n",
        "```python\n",
        "\"\"\"\n",
        "File: summarize_from_feedback/setup.py\n",
        "\"\"\"\n",
        "from setuptools import setup, find_packages\n",
        "\n",
        "setup(\n",
        "    name=\"summarize_from_feedback\",\n",
        "    py_modules=[\"summarize_from_feedback\"],\n",
        "    version=\"0.0.1\",\n",
        "    description=\"Code for 'Learning to Summarize from Human Feedback'\",\n",
        "    author=\"OpenAI\",\n",
        "    packages=find_packages(),\n",
        ")\n",
        "```\n",
        "\n",
        "\n",
        "2. Added `--allow-run-as-root` flag after the `str(H.mpi)` subprocess call in `summarize_from_feedback/summarize_from_feedback/utils/jobs.py`.\n",
        "\n",
        "```python\n",
        "\"\"\"\n",
        "File: summarize_from_feedback/summarize_from_feedback/utils/jobs.py\n",
        "\"\"\"\n",
        "\n",
        "subprocess.check_call(\n",
        "            [\n",
        "                \"mpiexec\",\n",
        "                \"-n\",\n",
        "                str(H.mpi),\n",
        "                \"--allow-run-as-root\",\n",
        "                \"python\",\n",
        "                \"-c\",\n",
        "                'import sys; import pickle; pickle.loads(open(\"/tmp/pickle_fn\", \"rb\").read())()',\n",
        "            ],\n",
        "\n",
        "```"
      ]
    }
  ]
}